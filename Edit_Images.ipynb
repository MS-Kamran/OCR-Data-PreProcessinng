{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Edit Images (grayscale > Threshold > Noise reduction > Increase contrast ) test**"
      ],
      "metadata": {
        "id": "tPflLZB3b4Hl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# USABLE BT NOT USE IN NEW **DATA**"
      ],
      "metadata": {
        "id": "X8qE_vcIb9x-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taUo-tLsbxe-"
      },
      "outputs": [],
      "source": [
        "\n",
        "#remove dots and save auto(threshold > grayscale > identify dots > binary image >  Noise reduction > Thresholding again)\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "\n",
        "def remove_dots_and_threshold(img_path, output_path):\n",
        "    # Read the image\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Threshold the image to identify dots\n",
        "    _, thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # Find contours in the binary image\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Loop through each contour\n",
        "    for contour in contours:\n",
        "        # If the contour area is small (indicating it's a dot), fill it with white color\n",
        "        if cv2.contourArea(contour) < 200:\n",
        "            cv2.drawContours(gray, [contour], 0, (255,255,255), -1)\n",
        "\n",
        "    # Noise reduction using morphological opening\n",
        "    #kernel = np.ones((math.ceil(.5), math.ceil(.5)), np.uint8)\n",
        "    kernel = np.ones((1, 1), np.uint8)\n",
        "    opened = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    # Thresholding again after removing noise\n",
        "    _, result = cv2.threshold(opened, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Save the result\n",
        "    cv2.imwrite(output_path, result)\n",
        "\n",
        "# Source directory containing images and destination directory to save processed images\n",
        "source_dir = '/Users/mskamran/Documents/Data Science/Page1 After pre proess'\n",
        "dest_dir = '/Users/mskamran/Documents/Data Science/res'\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "if not os.path.exists(dest_dir):\n",
        "    os.makedirs(dest_dir)\n",
        "\n",
        "# Iterate through each image in the source directory\n",
        "for filename in os.listdir(source_dir):\n",
        "    # Check if the file is an image (You can add more formats if needed)\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg'):\n",
        "        img_path = os.path.join(source_dir, filename)\n",
        "        output_path = os.path.join(dest_dir, filename)\n",
        "        remove_dots_and_threshold(img_path, output_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **For Normal Scanned image USED IN NEW DATA**"
      ],
      "metadata": {
        "id": "gakggZkhcME6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GrayScale With ONE Threshold Value**"
      ],
      "metadata": {
        "id": "aWYdYOSKcaV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def preprocess_image(img, threshold_value, noise_reduction_kernel_size, contrast_value):\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Threshold the image\n",
        "    _, thresh = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Noise reduction using morphological opening\n",
        "    kernel = np.ones((noise_reduction_kernel_size, noise_reduction_kernel_size), np.uint8)\n",
        "    opened = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    # Increase contrast\n",
        "    adjusted = cv2.convertScaleAbs(opened, alpha=contrast_value, beta=0)\n",
        "\n",
        "    return adjusted\n",
        "\n",
        "def process_image(img_path, output_path, threshold_value=127, noise_reduction_kernel_size=1, contrast_value=1.0):\n",
        "    # Read the image\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "    # Preprocess the image\n",
        "    processed_img = preprocess_image(img, threshold_value, noise_reduction_kernel_size, contrast_value)\n",
        "\n",
        "    # Save the result\n",
        "    cv2.imwrite(output_path, processed_img)\n",
        "\n",
        "# Source directory containing images and destination directory to save processed images\n",
        "source_dir = \"/Users/mskamran/Documents/Data Science/P2 process/Scanned\"\n",
        "dest_dir = '/Users/mskamran/Documents/Data Science/P2 process/Scanned Gray'\n",
        "\n",
        "# Define parameters\n",
        "threshold_value = 135\n",
        "noise_reduction_kernel_size = 1\n",
        "contrast_value = 1.0\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "if not os.path.exists(dest_dir):\n",
        "    os.makedirs(dest_dir)\n",
        "\n",
        "# Iterate through each image in the source directory\n",
        "for filename in os.listdir(source_dir):\n",
        "    # Check if the file is an image (You can add more formats if needed)\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg'):\n",
        "        img_path = os.path.join(source_dir, filename)\n",
        "        output_path = os.path.join(dest_dir, filename)\n",
        "        process_image(img_path, output_path, threshold_value, noise_reduction_kernel_size, contrast_value)\n"
      ],
      "metadata": {
        "id": "E_5k7gO-cN6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dot Remove (Identify Dots > Binary image > Thresholding again)"
      ],
      "metadata": {
        "id": "7O2IRMPrcpOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#remove dots and save auto(threshold > grayscale > identify dots > binary image >  Noise reduction > Thresholding again)\n",
        "#NOT PERFECT\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def remove_dots_and_threshold(img_path, output_path):\n",
        "    # Read the image\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Threshold the image to identify dots\n",
        "    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # Find contours in the binary image\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Loop through each contour\n",
        "    for contour in contours:\n",
        "        # If the contour area is small (indicating it's a dot), fill it with white color\n",
        "        if cv2.contourArea(contour) < 200:\n",
        "            cv2.drawContours(gray, [contour], 0, (255,255,255), -1)\n",
        "\n",
        "    # Noise reduction using morphological opening\n",
        "    kernel = np.ones((1, 1), np.uint8)\n",
        "    opened = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    # Thresholding again after removing noise\n",
        "    _, result = cv2.threshold(opened, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Save the result\n",
        "    cv2.imwrite(output_path, result)\n",
        "\n",
        "# Source directory containing images and destination directory to save processed images\n",
        "source_dir = '/Users/mskamran/Documents/Data Science/P2 Process/Scanned gray'\n",
        "dest_dir = '/Users/mskamran/Documents/Data Science/P2 Process/Scan remove dot'\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "if not os.path.exists(dest_dir):\n",
        "    os.makedirs(dest_dir)\n",
        "\n",
        "# Iterate through each image in the source directory\n",
        "for filename in os.listdir(source_dir):\n",
        "    # Check if the file is an image (You can add more formats if needed)\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg'):\n",
        "        img_path = os.path.join(source_dir, filename)\n",
        "        output_path = os.path.join(dest_dir, filename)\n",
        "        remove_dots_and_threshold(img_path, output_path)\n"
      ],
      "metadata": {
        "id": "2-sTJuwycpkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GOOD to USE  Dot Remove"
      ],
      "metadata": {
        "id": "REnjwxGQcvHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#PERFECT AND GOOD\n",
        "\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def remove_dots_and_threshold(img_path, output_path):\n",
        "    # Read the image\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Threshold the image to identify dots\n",
        "    _, thresh = cv2.threshold(gray, 5, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # Find contours in the binary image\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Loop through each contour\n",
        "    for contour in contours:\n",
        "        # If the contour area is small (indicating it's a dot), fill it with white color\n",
        "        if cv2.contourArea(contour) < 150:\n",
        "            cv2.drawContours(gray, [contour], 0, (255,255,255), -1)\n",
        "\n",
        "    # Noise reduction using morphological opening\n",
        "    kernel = np.ones((1, 1), np.uint8)\n",
        "    opened = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    # Save the result\n",
        "    cv2.imwrite(output_path, opened)\n",
        "\n",
        "# Source directory containing images and destination directory to save processed images\n",
        "source_dir = '/Users/mskamran/Documents/Data Science/P2 Process/Scanned gray'\n",
        "dest_dir = '/Users/mskamran/Documents/Data Science/P2 Process/Scan remove dot'\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "if not os.path.exists(dest_dir):\n",
        "    os.makedirs(dest_dir)\n",
        "\n",
        "# Iterate through each image in the source directory\n",
        "for filename in os.listdir(source_dir):\n",
        "    # Check if the file is an image (You can add more formats if needed)\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg'):\n",
        "        img_path = os.path.join(source_dir, filename)\n",
        "        output_path = os.path.join(dest_dir, filename)\n",
        "        remove_dots_and_threshold(img_path, output_path)\n"
      ],
      "metadata": {
        "id": "Vi9cZyT5cvWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For Mobile Image"
      ],
      "metadata": {
        "id": "2BQu30ycc3xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dir = '/Users/mskamran/Documents/Data Science/P2 Process/Old Data/T1'\n",
        "output_dir = '/Users/mskamran/Documents/Data Science/P2 Process/Old Data/T1 Try'"
      ],
      "metadata": {
        "id": "DzPR4tq8c97j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def preprocess_image(img, threshold_value, noise_reduction_kernel_size, contrast_value):\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Threshold the image\n",
        "    _, thresh = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Noise reduction using morphological opening\n",
        "    kernel = np.ones((noise_reduction_kernel_size, noise_reduction_kernel_size), np.uint8)\n",
        "    opened = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    # Increase contrast\n",
        "    adjusted = cv2.convertScaleAbs(opened, alpha=contrast_value, beta=0)\n",
        "\n",
        "    return adjusted\n",
        "\n",
        "def sharpen_image(img):\n",
        "    # Define the sharpening kernel\n",
        "    kernel_sharpening = np.array([[-1,-1,-1],\n",
        "                                  [-1, 9,-1],\n",
        "                                  [-1,-1,-1]])\n",
        "\n",
        "    # Apply the sharpening kernel\n",
        "    sharpened_img = cv2.filter2D(img, -1, kernel_sharpening)\n",
        "    return sharpened_img\n",
        "\n",
        "def process_image(img_path, output_path, threshold_value=130, noise_reduction_kernel_size=1, contrast_value=1.0):\n",
        "    # Read the image\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "    # Preprocess the image\n",
        "    processed_img = preprocess_image(img, threshold_value, noise_reduction_kernel_size, contrast_value)\n",
        "\n",
        "    # Sharpen the processed image\n",
        "    sharpened_img = sharpen_image(processed_img)\n",
        "\n",
        "    # Save the result\n",
        "    cv2.imwrite(output_path, sharpened_img)\n",
        "\n",
        "# Source directory containing images and destination directory to save processed images\n",
        "source_dir = '/Users/mskamran/Documents/Data Science/P2 Process/Old Data/T1'\n",
        "dest_dir = '/Users/mskamran/Documents/Data Science/P2 Process/Old Data/T1 Gray'\n",
        "\n",
        "# Define parameters\n",
        "threshold_value = 130\n",
        "noise_reduction_kernel_size = 1\n",
        "contrast_value = 1.0\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "if not os.path.exists(dest_dir):\n",
        "    os.makedirs(dest_dir)\n",
        "\n",
        "# Iterate through each image in the source directory\n",
        "for filename in os.listdir(source_dir):\n",
        "    # Check if the file is an image (You can add more formats if needed)\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg'):\n",
        "        img_path = os.path.join(source_dir, filename)\n",
        "        output_path = os.path.join(dest_dir, filename)\n",
        "        process_image(img_path, output_path, threshold_value, noise_reduction_kernel_size, contrast_value)"
      ],
      "metadata": {
        "id": "5yy2urlWc4Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove dots and save auto(threshold > grayscale > identify dots > binary image >  Noise reduction > Thresholding again)\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def remove_dots_and_threshold(img_path, output_path):\n",
        "    # Read the image\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Threshold the image to identify dots\n",
        "    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # Find contours in the binary image\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Loop through each contour\n",
        "    for contour in contours:\n",
        "        # If the contour area is small (indicating it's a dot), fill it with white color\n",
        "        if cv2.contourArea(contour) < 200:  #200\n",
        "            cv2.drawContours(gray, [contour], 0, (255,255,255), -1)\n",
        "\n",
        "    # Noise reduction using morphological opening\n",
        "    kernel = np.ones((1, 1), np.uint8)\n",
        "    opened = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    # Thresholding again after removing noise\n",
        "    _, result = cv2.threshold(opened, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Save the result\n",
        "    cv2.imwrite(output_path, result)\n",
        "\n",
        "# Source directory containing images and destination directory to save processed images\n",
        "source_dir = '/Users/mskamran/Documents/Data Science/P2 Process/Old Data/T1 Gray'\n",
        "dest_dir = '/Users/mskamran/Documents/Data Science/P2 Process/Old Data/T1 RemoveDot'\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "if not os.path.exists(dest_dir):\n",
        "    os.makedirs(dest_dir)\n",
        "\n",
        "# Iterate through each image in the source directory\n",
        "for filename in os.listdir(source_dir):\n",
        "    # Check if the file is an image (You can add more formats if needed)\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg'):\n",
        "        img_path = os.path.join(source_dir, filename)\n",
        "        output_path = os.path.join(dest_dir, filename)\n",
        "        remove_dots_and_threshold(img_path, output_path)\n"
      ],
      "metadata": {
        "id": "GqlBiuz9c6nK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **For Black and white with 4 Thrashold Vlaue**"
      ],
      "metadata": {
        "id": "4V51huiDdW19"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Scanned Images Thrashold 4 Values**"
      ],
      "metadata": {
        "id": "Zd0ys6T9d9cc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def multi_level_thresholding(input_dir, output_dir, thresholds):\n",
        "    # Ensure output directory exists\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Process each image in the input directory\n",
        "    for filename in os.listdir(input_dir):\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
        "            image_path = os.path.join(input_dir, filename)\n",
        "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if image is None:\n",
        "                print(f\"Skipped (unable to read): {image_path}\")\n",
        "                continue\n",
        "\n",
        "            # Initialize an empty array for the output image\n",
        "            output_image = np.zeros_like(image)\n",
        "\n",
        "            # Apply multi-level thresholding\n",
        "            for i, thresh in enumerate(sorted(thresholds)):\n",
        "                if i == 0:\n",
        "                    output_image[image <= thresh] = i * (255 // len(thresholds))\n",
        "                else:\n",
        "                    output_image[(image > sorted(thresholds)[i-1]) & (image <= thresh)] = i * (255 // len(thresholds))\n",
        "            output_image[image > sorted(thresholds)[-1]] = len(thresholds) * (255 // len(thresholds))\n",
        "\n",
        "            # Save the processed image to the output directory\n",
        "            output_path = os.path.join(output_dir, filename)\n",
        "            cv2.imwrite(output_path, output_image)\n",
        "            print(f\"Processed and saved: {output_path}\")\n",
        "\n",
        "# Replace these paths with your actual directories\n",
        "input_dir = '/Users/mskamran/Documents/Data Science/P2 Process/Scanned'\n",
        "output_dir = '/Users/mskamran/Documents/Data Science/P2 Process/Scanned try'\n",
        "\n",
        "# Define your thresholds (values should be between 0 and 255)\n",
        "thresholds = [100, 150, 200]\n",
        "\n",
        "#this one is used [100, 150, 200]\n",
        "#[90, 130, 150, 170]\n",
        "#Good [90, 100, 150, 170]\n",
        "#[50, 100, 150, 200]\n",
        "#[50, 100, 150, 170]\n",
        "#[75, 100, 150, 175]\n",
        "#[75, 100, 130, 170]\n",
        "#[40, 80, 120, 160, 200, 240]\n",
        "#[50, 100, 150, 175]\n",
        "\n",
        "multi_level_thresholding(input_dir, output_dir, thresholds)\n"
      ],
      "metadata": {
        "id": "oR0lVUdpeVS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dot remove**"
      ],
      "metadata": {
        "id": "Uo-h3rSYeMoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def remove_dots(img_path, output_path, threshold_value=180, dot_area_threshold=200, noise_reduction_kernel_size=3):\n",
        "    # Read the image\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to identify dots\n",
        "    _, thresh = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # Find contours in the binary image\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Loop through each contour\n",
        "    for contour in contours:\n",
        "        # If the contour area is small (indicating it's a dot), fill it with white color\n",
        "        if cv2.contourArea(contour) < dot_area_threshold:\n",
        "            cv2.drawContours(gray, [contour], 0, (255,255,255), -1)\n",
        "\n",
        "    # Noise reduction using morphological opening\n",
        "    kernel = np.ones((noise_reduction_kernel_size, noise_reduction_kernel_size), np.uint8)\n",
        "    opened = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    # Save the result without applying the final thresholding\n",
        "    cv2.imwrite(output_path, opened)\n",
        "\n",
        "# Source directory containing images and destination directory to save processed images\n",
        "source_dir = '/Users/mskamran/Documents/Data Science/P2 Process/Scanned gray'\n",
        "dest_dir = '/Users/mskamran/Documents/Data Science/P2 Process/Scan remove dot'\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "if not os.path.exists(dest_dir):\n",
        "    os.makedirs(dest_dir)\n",
        "\n",
        "# Iterate through each image in the source directory\n",
        "for filename in os.listdir(source_dir):\n",
        "    # Check if the file is an image (You can add more formats if needed)\n",
        "    if filename.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "        img_path = os.path.join(source_dir, filename)\n",
        "        output_path = os.path.join(dest_dir, filename)\n",
        "        remove_dots(img_path, output_path)"
      ],
      "metadata": {
        "id": "ChwXokhEdXpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **For Mobile**"
      ],
      "metadata": {
        "id": "FaVYHOQneibl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def multi_level_thresholding(input_dir, output_dir, thresholds):\n",
        "    # Ensure output directory exists\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Process each image in the input directory\n",
        "    for filename in os.listdir(input_dir):\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
        "            image_path = os.path.join(input_dir, filename)\n",
        "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if image is None:\n",
        "                print(f\"Skipped (unable to read): {image_path}\")\n",
        "                continue\n",
        "\n",
        "            # Initialize an empty array for the output image\n",
        "            output_image = np.zeros_like(image)\n",
        "\n",
        "            # Apply multi-level thresholding\n",
        "            for i, thresh in enumerate(sorted(thresholds)):\n",
        "                if i == 0:\n",
        "                    output_image[image <= thresh] = i * (255 // len(thresholds))\n",
        "                else:\n",
        "                    output_image[(image > sorted(thresholds)[i-1]) & (image <= thresh)] = i * (255 // len(thresholds))\n",
        "            output_image[image > sorted(thresholds)[-1]] = len(thresholds) * (255 // len(thresholds))\n",
        "\n",
        "            # Save the processed image to the output directory\n",
        "            output_path = os.path.join(output_dir, filename)\n",
        "            cv2.imwrite(output_path, output_image)\n",
        "            print(f\"Processed and saved: {output_path}\")\n",
        "\n",
        "# Replace these paths with your actual directories\n",
        "input_dir = '/Users/mskamran/Documents/Data Science/P2 Process/Old Data/T2'\n",
        "output_dir = '/Users/mskamran/Documents/Data Science/P2 Process/Old Data/T2 gray'\n",
        "\n",
        "# Define your thresholds (values should be between 0 and 255)\n",
        "thresholds = [55, 105, 140]\n",
        "\n",
        " #For Mobile [75, 125, 150]\n",
        "\n",
        "  #this one is used [100, 150, 200]\n",
        " #[90, 130, 150, 170]\n",
        " #Good [90, 100, 150, 170]\n",
        "\n",
        " #[50, 100, 150, 170]\n",
        "\n",
        "\n",
        "#[75, 100, 150, 175]\n",
        " #[75, 100, 130, 170]\n",
        "\n",
        " #[40, 80, 120, 160, 200, 240]\n",
        "#[50, 100, 150, 175]\n",
        "\n",
        "multi_level_thresholding(input_dir, output_dir, thresholds)\n"
      ],
      "metadata": {
        "id": "rx0_D5R1ejRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mobile Dot Remove Normal New Data**"
      ],
      "metadata": {
        "id": "VtrkFrfuer0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def remove_dots(img_path, output_path, threshold_value=180, dot_area_threshold=200, noise_reduction_kernel_size=3):\n",
        "    # Read the image\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to identify dots\n",
        "    _, thresh = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # Find contours in the binary image\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Loop through each contour\n",
        "    for contour in contours:\n",
        "        # If the contour area is small (indicating it's a dot), fill it with white color\n",
        "        if cv2.contourArea(contour) < dot_area_threshold:\n",
        "            cv2.drawContours(gray, [contour], 0, (255,255,255), -1)\n",
        "\n",
        "    # Noise reduction using morphological opening\n",
        "    kernel = np.ones((noise_reduction_kernel_size, noise_reduction_kernel_size), np.uint8)\n",
        "    opened = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    # Save the result without applying the final thresholding\n",
        "    cv2.imwrite(output_path, opened)\n",
        "\n",
        "# Source directory containing images and destination directory to save processed images\n",
        "source_dir = '/Users/mskamran/Documents/Data Science/P2 Process/Old Data/T2 gray'\n",
        "dest_dir = '/Users/mskamran/Documents/Data Science/P2 Process/Old Data/T2 dot remove'\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "if not os.path.exists(dest_dir):\n",
        "    os.makedirs(dest_dir)\n",
        "\n",
        "# Iterate through each image in the source directory\n",
        "for filename in os.listdir(source_dir):\n",
        "    # Check if the file is an image (You can add more formats if needed)\n",
        "    if filename.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "        img_path = os.path.join(source_dir, filename)\n",
        "        output_path = os.path.join(dest_dir, filename)\n",
        "        remove_dots(img_path, output_path)\n"
      ],
      "metadata": {
        "id": "nB0ylAqoew77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mobile Old Data T1**"
      ],
      "metadata": {
        "id": "xaQDo3bbe7SJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def multi_level_thresholding(input_dir, output_dir, thresholds):\n",
        "    # Ensure output directory exists\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Process each image in the input directory\n",
        "    for filename in os.listdir(input_dir):\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
        "            image_path = os.path.join(input_dir, filename)\n",
        "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if image is None:\n",
        "                print(f\"Skipped (unable to read): {image_path}\")\n",
        "                continue\n",
        "\n",
        "            # Initialize an empty array for the output image\n",
        "            output_image = np.zeros_like(image)\n",
        "\n",
        "            # Apply multi-level thresholding\n",
        "            for i, thresh in enumerate(sorted(thresholds)):\n",
        "                if i == 0:\n",
        "                    output_image[image <= thresh] = i * (255 // len(thresholds))\n",
        "                else:\n",
        "                    output_image[(image > sorted(thresholds)[i-1]) & (image <= thresh)] = i * (255 // len(thresholds))\n",
        "            output_image[image > sorted(thresholds)[-1]] = len(thresholds) * (255 // len(thresholds))\n",
        "\n",
        "            # Save the processed image to the output directory\n",
        "            output_path = os.path.join(output_dir, filename)\n",
        "            cv2.imwrite(output_path, output_image)\n",
        "            print(f\"Processed and saved: {output_path}\")\n",
        "\n",
        "# Replace these paths with your actual directories\n",
        "input_dir = '/Users/mskamran/Documents/Data Science/P2 Process/Old Data/T1'\n",
        "output_dir = '/Users/mskamran/Documents/Data Science/P2 Process/Old Data/T1 gray'\n",
        "\n",
        "# Define your thresholds (values should be between 0 and 255)\n",
        "thresholds = [55, 105, 140]\n",
        "\n",
        " #For Mobile [75, 125, 150]\n",
        "\n",
        "  #this one is used [100, 150, 200]\n",
        " #[90, 130, 150, 170]\n",
        " #Good [90, 100, 150, 170]\n",
        "\n",
        " #[50, 100, 150, 170]\n",
        "\n",
        "\n",
        "#[75, 100, 150, 175]\n",
        " #[75, 100, 130, 170]\n",
        "\n",
        " #[40, 80, 120, 160, 200, 240]\n",
        "#[50, 100, 150, 175]\n",
        "\n",
        "multi_level_thresholding(input_dir, output_dir, thresholds)\n"
      ],
      "metadata": {
        "id": "CvITuRrKe7p7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mobile Old Data T2**"
      ],
      "metadata": {
        "id": "T-ZNIFwefEv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def multi_level_thresholding(input_dir, output_dir, thresholds):\n",
        "    # Ensure output directory exists\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Process each image in the input directory\n",
        "    for filename in os.listdir(input_dir):\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
        "            image_path = os.path.join(input_dir, filename)\n",
        "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if image is None:\n",
        "                print(f\"Skipped (unable to read): {image_path}\")\n",
        "                continue\n",
        "\n",
        "            # Initialize an empty array for the output image\n",
        "            output_image = np.zeros_like(image)\n",
        "\n",
        "            # Apply multi-level thresholding\n",
        "            for i, thresh in enumerate(sorted(thresholds)):\n",
        "                if i == 0:\n",
        "                    output_image[image <= thresh] = i * (255 // len(thresholds))\n",
        "                else:\n",
        "                    output_image[(image > sorted(thresholds)[i-1]) & (image <= thresh)] = i * (255 // len(thresholds))\n",
        "            output_image[image > sorted(thresholds)[-1]] = len(thresholds) * (255 // len(thresholds))\n",
        "\n",
        "            # Save the processed image to the output directory\n",
        "            output_path = os.path.join(output_dir, filename)\n",
        "            cv2.imwrite(output_path, output_image)\n",
        "            print(f\"Processed and saved: {output_path}\")\n",
        "\n",
        "# Replace these paths with your actual directories\n",
        "input_dir = '/Users/mskamran/Documents/Data Science/P2 Process/Old Data/T1'\n",
        "output_dir = '/Users/mskamran/Documents/Data Science/P2 Process/Old Data/T1 gray'\n",
        "\n",
        "# Define your thresholds (values should be between 0 and 255)\n",
        "thresholds = [55, 105, 130]\n",
        "\n",
        " #For Mobile [75, 125, 150]\n",
        "\n",
        "  #this one is used [100, 150, 200]\n",
        " #[90, 130, 150, 170]\n",
        " #Good [90, 100, 150, 170]\n",
        "\n",
        " #[50, 100, 150, 170]\n",
        "\n",
        "\n",
        "#[75, 100, 150, 175]\n",
        " #[75, 100, 130, 170]\n",
        "\n",
        " #[40, 80, 120, 160, 200, 240]\n",
        "#[50, 100, 150, 175]\n",
        "\n",
        "multi_level_thresholding(input_dir, output_dir, thresholds)\n"
      ],
      "metadata": {
        "id": "FJUuVJw2fGAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Calculate average Stroke values in One Image**"
      ],
      "metadata": {
        "id": "5lmzNj1HfMU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def calculate_threshold_percentages(image_path, thresholds):\n",
        "    # Read the image in grayscale\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # Initialize a dictionary to store the counts\n",
        "    counts = {thresh: 0 for thresh in thresholds}\n",
        "    counts['>200'] = 0\n",
        "\n",
        "    # Count the pixels in each threshold range\n",
        "    for i, thresh in enumerate(sorted(thresholds)):\n",
        "        if i == 0:\n",
        "            counts[thresh] = np.sum(image <= thresh)\n",
        "        else:\n",
        "            counts[thresh] = np.sum((image > sorted(thresholds)[i-1]) & (image <= thresh))\n",
        "    counts['>200'] = np.sum(image > sorted(thresholds)[-1])\n",
        "\n",
        "    # Calculate the total number of pixels\n",
        "    total_pixels = image.shape[0] * image.shape[1]\n",
        "\n",
        "    # Calculate the percentages\n",
        "    percentages = {thresh: (count / total_pixels) * 100 for thresh, count in counts.items()}\n",
        "\n",
        "    return percentages\n",
        "\n",
        "# Replace this with the path to your actual image\n",
        "image_path = '/Users/mskamran/Documents/Data Science/P2 Process/Compare/s/Rajshahsi_Rajshashi Court Academy School RCAS_C8_M_C14_P2_2858 copy.jpg'\n",
        "\n",
        "# Define your thresholds\n",
        "thresholds = [100, 150, 200]\n",
        "\n",
        "# Calculate the threshold percentages\n",
        "percentages = calculate_threshold_percentages(image_path, thresholds)\n",
        "\n",
        "# Print the results\n",
        "for thresh, percentage in percentages.items():\n",
        "    print(f\"Percentage of pixels with values {'<=' if thresh != '>200' else '>'} {thresh}: {percentage:.2f}%\")"
      ],
      "metadata": {
        "id": "UaHyKXu-fQd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **For Color thresholds 3 color 4 values**"
      ],
      "metadata": {
        "id": "KWZ-13L4fkCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def multi_level_thresholding_rgb(input_dir, output_dir, thresholds):\n",
        "    # Ensure output directory exists\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Process each image in the input directory\n",
        "    for filename in os.listdir(input_dir):\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
        "            image_path = os.path.join(input_dir, filename)\n",
        "            image = cv2.imread(image_path)\n",
        "            if image is None:\n",
        "                print(f\"Skipped (unable to read): {image_path}\")\n",
        "                continue\n",
        "\n",
        "            # Split the image into R, G, B channels\n",
        "            b_channel, g_channel, r_channel = cv2.split(image)\n",
        "\n",
        "            # Function to apply multi-level thresholding to a single channel\n",
        "            def apply_threshold(channel):\n",
        "                output_channel = np.zeros_like(channel)\n",
        "                for i, thresh in enumerate(sorted(thresholds)):\n",
        "                    if i == 0:\n",
        "                        output_channel[channel <= thresh] = i * (255 // len(thresholds))\n",
        "                    else:\n",
        "                        output_channel[(channel > sorted(thresholds)[i-1]) & (channel <= thresh)] = i * (255 // len(thresholds))\n",
        "                output_channel[channel > sorted(thresholds)[-1]] = len(thresholds) * (255 // len(thresholds))\n",
        "                return output_channel\n",
        "\n",
        "            # Apply multi-level thresholding to each channel\n",
        "            r_channel_thresh = apply_threshold(r_channel)\n",
        "            g_channel_thresh = apply_threshold(g_channel)\n",
        "            b_channel_thresh = apply_threshold(b_channel)\n",
        "\n",
        "            # Merge the thresholded channels back into an RGB image\n",
        "            output_image = cv2.merge([b_channel_thresh, g_channel_thresh, r_channel_thresh])\n",
        "\n",
        "            # Save the processed image to the output directory\n",
        "            output_path = os.path.join(output_dir, filename)\n",
        "            cv2.imwrite(output_path, output_image)\n",
        "            print(f\"Processed and saved: {output_path}\")\n",
        "\n",
        "# Replace these paths with your actual directories\n",
        "input_dir = '/Users/mskamran/Documents/Data Science/P2 Process/Scanned'\n",
        "output_dir = '/Users/mskamran//Documents/Data Science/P2 Process/Old Data/Try'\n",
        "\n",
        "# Define your thresholds (values should be between 0 and 255)\n",
        "thresholds = [50, 100, 150, 200]\n",
        "\n",
        "multi_level_thresholding_rgb(input_dir, output_dir, thresholds)\n"
      ],
      "metadata": {
        "id": "JcL193eTfoEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Just Noise Reduction**"
      ],
      "metadata": {
        "id": "KuVAF7d-g8e_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Source and destination directories\n",
        "source_dir = '/Users/mskamran/Documents/Data Science/final letters process/Akshar Porichoy/Test'\n",
        "destination_dir = '/Users/mskamran/Documents/Data Science/final letters process/Akshar Porichoy/Test copy'\n",
        "\n",
        "# Create destination directory if it doesn't exist\n",
        "if not os.path.exists(destination_dir):\n",
        "    os.makedirs(destination_dir)\n",
        "\n",
        "# Function to remove noise from an image\n",
        "def remove_noise(image):\n",
        "    # Convert image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Threshold the image to create a binary mask\n",
        "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "\n",
        "    # Perform morphological operations to remove small noise\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "    cleaned = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "\n",
        "    return cleaned\n",
        "\n",
        "# Iterate through each file in the source directory\n",
        "for filename in os.listdir(source_dir):\n",
        "    # Check if the file is an image\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg'):\n",
        "        # Read the image\n",
        "        img = cv2.imread(os.path.join(source_dir, filename))\n",
        "\n",
        "        # Remove noise from the image\n",
        "        cleaned_img = remove_noise(img)\n",
        "\n",
        "        # Save the cleaned image to the destination directory\n",
        "        cv2.imwrite(os.path.join(destination_dir, filename), cleaned_img)\n",
        "\n",
        "print(\"Noise removal completed.\")\n"
      ],
      "metadata": {
        "id": "mhQUeWl0g88x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "def remove_small_black_noise(input_folder, output_folder, threshold_area):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Iterate through each file in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
        "            # Read the image\n",
        "            img_path = os.path.join(input_folder, filename)\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            # Threshold the image\n",
        "            _, thresh = cv2.threshold(img, 1, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "            # Find contours\n",
        "            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "            # Iterate through each contour\n",
        "            for contour in contours:\n",
        "                # Calculate area of contour\n",
        "                area = cv2.contourArea(contour)\n",
        "                # If contour area is less than threshold area, fill it with white\n",
        "                if area < threshold_area:\n",
        "                    cv2.drawContours(img, [contour], 0, (255, 255, 255), -1)\n",
        "\n",
        "            # Save the cleaned image to output folder\n",
        "            output_path = os.path.join(output_folder, filename)\n",
        "            cv2.imwrite(output_path, img)\n",
        "\n",
        "# Define input and output folders\n",
        "input_folder = '/Users/mskamran/Documents/Data Science/final letters process/Akshar Porichoy/Test'\n",
        "output_folder = '/Users/mskamran/Documents/Data Science/final letters process/Akshar Porichoy/Test copy'\n",
        "\n",
        "# Define threshold area for noise removal\n",
        "threshold_area = 100  # Adjust this threshold as needed\n",
        "\n",
        "# Call the function\n",
        "remove_small_black_noise(input_folder, output_folder, threshold_area)\n"
      ],
      "metadata": {
        "id": "Buwz7w3ig_t4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "def remove_small_black_contours(input_folder, output_folder, threshold_area):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Iterate through each file in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
        "            # Read the image\n",
        "            img_path = os.path.join(input_folder, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Threshold the image\n",
        "            _, thresh = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "            # Find contours\n",
        "            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "            # Iterate through each contour\n",
        "            for contour in contours:\n",
        "                # Calculate area of contour\n",
        "                area = cv2.contourArea(contour)\n",
        "                # If contour area is less than threshold area and color is black, fill it with white\n",
        "                if area < threshold_area and cv2.mean(img, mask=thresh)[0] < 100:\n",
        "                    cv2.drawContours(img, [contour], 0, (255, 255, 255), -1)\n",
        "\n",
        "            # Save the cleaned image to output folder\n",
        "            output_path = os.path.join(output_folder, filename)\n",
        "            cv2.imwrite(output_path, img)\n",
        "\n",
        "# Define input and output folders\n",
        "input_folder = '/Users/mskamran/Documents/Data Science/final letters process/Akshar Porichoy/Test'\n",
        "output_folder = '/Users/mskamran/Documents/Data Science/final letters process/Akshar Porichoy/Test copy'\n",
        "\n",
        "# Define threshold area for noise removal\n",
        "threshold_area = 100  # Adjust this threshold as needed\n",
        "\n",
        "# Call the function\n",
        "remove_small_black_contours(input_folder, output_folder, threshold_area)\n"
      ],
      "metadata": {
        "id": "bd8RaQ49hCR4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}