{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Google Drive Mount**"
      ],
      "metadata": {
        "id": "LDNDHsjgE4Zs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lHLUKJt5E3U6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Check All Letters are in the Tempalte**"
      ],
      "metadata": {
        "id": "wPYsa5wkEkwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check all letters are in the tempalte\n",
        "\n",
        "def count_letters_in_string(input_string, letter_array):\n",
        "    letter_count = {}\n",
        "    not_found_letters = set(letter_array)  # Initialize with all letters\n",
        "\n",
        "    # Convert the input string to lowercase for case-insensitive matching\n",
        "    input_string = input_string.lower()\n",
        "\n",
        "    # Iterate through the string characters\n",
        "    for char in input_string:\n",
        "        if char in letter_array:\n",
        "            if char in letter_count:\n",
        "                letter_count[char] += 1\n",
        "            else:\n",
        "                letter_count[char] = 1\n",
        "            not_found_letters.discard(char)  # Remove the found letter from the set\n",
        "\n",
        "    return letter_count, list(not_found_letters)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Define the letter array\n",
        "    letter_array = [\n",
        "    'অ', 'আ', 'ই', 'ঈ', 'উ', 'ঊ',\n",
        "    'ঋ', 'এ', 'ঐ', 'ও', 'ঔ', 'ক',\n",
        "    'খ', 'গ', 'ঘ', 'ঙ', 'চ', 'ছ',\n",
        "    'জ', 'ঝ', 'ঞ', 'ট', 'ঠ', 'ড',\n",
        "    'ঢ', 'ণ', 'ত', 'থ', 'দ', 'ধ',\n",
        "    'ন', 'প', 'ফ', 'ব', 'ভ', 'ম',\n",
        "    'য', 'র', 'ল', 'শ', 'ষ', 'স',\n",
        "    'হ', 'ড়', 'ঢ়', 'য়', 'ৎ', 'ং',\n",
        "    'ো', 'ঁ', 'া', 'ি', 'ী', 'ু',\n",
        "    'ে', 'ৈ', 'ো', 'ৌ', '‍্য', '্র',\n",
        "    'ূ', 'ৃ']\n",
        "\n",
        "    # Get the input string from the user\n",
        "    input_string = input(\"Enter a string: \")\n",
        "\n",
        "    # Call the function to count the letters in the string and find missing letters\n",
        "    letter_count, not_found_letters = count_letters_in_string(input_string, letter_array)\n",
        "\n",
        "    # Display the result\n",
        "    for letter, count in letter_count.items():\n",
        "        print(f\"'{letter}' appears {count} times in the input string.\")\n",
        "\n",
        "    if not_found_letters:\n",
        "        print(\"Letters not found in the input string:\")\n",
        "        print(not_found_letters)\n",
        "        print(f\"Number of letters not found: {len(not_found_letters)}\")"
      ],
      "metadata": {
        "id": "_N0gXGW3Eh6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_letters_in_string(input_string, letter_array):\n",
        "    letter_count = {}\n",
        "    not_found_letters = set(letter_array)  # Initialize with all letters\n",
        "\n",
        "    # Convert the input string to lowercase for case-insensitive matching\n",
        "    input_string = input_string.lower()\n",
        "\n",
        "    # Iterate through the string characters\n",
        "    for char in input_string:\n",
        "        if char in letter_array:\n",
        "            if char in letter_count:\n",
        "                letter_count[char] += 1\n",
        "            else:\n",
        "                letter_count[char] = 1\n",
        "            not_found_letters.discard(char)  # Remove the found letter from the set\n",
        "\n",
        "    return letter_count, list(not_found_letters)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Define the letter array\n",
        "    letter_array = [ 'ড', '্র', 'ৎ', 'য়', 'ঁ', 'ঝ', 'ঐ', 'ঠ', 'থ', 'ঋ', 'উ', 'ঘ', 'ঞ', 'ফ', 'ৌ', 'ো', 'ঙ', 'ৈ', 'আ', 'চ', 'ঢ়', 'ঔ', 'ঈ', 'ঊ', 'ড়', '‍্য', 'ঃ']\n",
        "\n",
        "    # Get the input string from the user\n",
        "    input_string = input(\"Enter a string: \")\n",
        "\n",
        "    # Call the function to count the letters in the string and find missing letters\n",
        "    letter_count, not_found_letters = count_letters_in_string(input_string, letter_array)\n",
        "\n",
        "    # Display the result\n",
        "    for letter, count in letter_count.items():\n",
        "        print(f\"'{letter}' appears {count} times in the input string.\")\n",
        "\n",
        "    if not_found_letters:\n",
        "        print(\"Letters not found in the input string:\")\n",
        "        print(not_found_letters)\n",
        "        print(f\"Number of letters not found: {len(not_found_letters)}\")"
      ],
      "metadata": {
        "id": "5hhTwlRwEtsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Count How may Images Are in the Folder**"
      ],
      "metadata": {
        "id": "0rMRiMc_r_QB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N35nUY6srHTJ"
      },
      "outputs": [],
      "source": [
        "# prompt: write a code which will iterate every folder and count how many imagses are in the folder\n",
        "\n",
        "import os\n",
        "\n",
        "def count_images(folder_path):\n",
        "  \"\"\"\n",
        "  Counts the number of images in a folder and its subfolders.\n",
        "\n",
        "  Args:\n",
        "    folder_path: The path to the folder.\n",
        "\n",
        "  Returns:\n",
        "    The total number of images in the folder and its subfolders.\n",
        "  \"\"\"\n",
        "\n",
        "  total_images = 0\n",
        "  for root, dirs, files in os.walk(folder_path):\n",
        "    for file in files:\n",
        "      if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
        "        total_images += 1\n",
        "\n",
        "  return total_images\n",
        "\n",
        "# Example usage\n",
        "folder_path = \"/Users/mskamran/Documents/Data Science/Raw\"\n",
        "num_images = count_images(folder_path)\n",
        "print(f\"Total images: {num_images}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Count How many Folders Are in an Folder**"
      ],
      "metadata": {
        "id": "_066eyAp40B2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def count_folders(folder_path):\n",
        "    # Initialize a counter for folders\n",
        "    folder_count = 0\n",
        "\n",
        "    # Iterate over the items in the folder\n",
        "    for item in os.listdir(folder_path):\n",
        "        # Join the folder path with the item name\n",
        "        item_path = os.path.join(folder_path, item)\n",
        "        # Check if the item is a directory\n",
        "        if os.path.isdir(item_path):\n",
        "            # If it's a directory, increment the folder count\n",
        "            folder_count += 1\n",
        "\n",
        "    return folder_count\n",
        "\n",
        "# Specify the path to the folder you want to count folders in\n",
        "folder_path = \"//Users/mskamran/Documents/Data Science/letters in different quality image/28*28 letter by augmentation\"  # Change this to the path of your folder\n",
        "\n",
        "# Call the function to count the folders\n",
        "num_folders = count_folders(folder_path)\n",
        "print(f\"Number of folders in '{folder_path}': {num_folders}\")\n"
      ],
      "metadata": {
        "id": "KkLDksd15AKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lebel According to the Folder Name**\n"
      ],
      "metadata": {
        "id": "XgmLJb_LsIds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Concatenates the folder names with the serial number and the original filename to create a new name. This results in a longer name that includes the directory structure.\n",
        "# Uses the full directory path in the new name.\n",
        "\n",
        "import os\n",
        "\n",
        "def rename_images(root_dir):\n",
        "    for root, dirs, files in os.walk(root_dir):\n",
        "        serial_number = 1\n",
        "        for filename in files:\n",
        "            if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
        "                folder_names = root.split(os.path.sep)\n",
        "                new_name = '_'.join(folder_names) + '_' + str(serial_number) + '_' + filename\n",
        "                old_path = os.path.join(root, filename)\n",
        "                new_path = os.path.join(root, new_name)\n",
        "                os.rename(old_path, new_path)\n",
        "                print(\"Serial Number:\", serial_number, \"New Name:\", new_name)\n",
        "                serial_number += 1\n",
        "\n",
        "# Replace 'root_dir' with the directory you want to start from\n",
        "root_dir = '/Users/mskamran/Documents/Data Science/Raw'\n",
        "rename_images(root_dir)\n"
      ],
      "metadata": {
        "id": "OhRj0F23s1se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Only adds the serial number to the original filename.\n",
        "#Does not include the directory structure in the new name.\n",
        "\n",
        "import os\n",
        "\n",
        "def rename_images(root_dir):\n",
        "    for root, dirs, files in os.walk(root_dir):\n",
        "        serial_number = 1\n",
        "        for filename in files:\n",
        "            if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
        "                new_name = str(serial_number) + '_' + filename\n",
        "                old_path = os.path.join(root, filename)\n",
        "                new_path = os.path.join(root, new_name)\n",
        "                os.rename(old_path, new_path)\n",
        "                print(\"Serial Number:\", serial_number, \"New Name:\", new_name)\n",
        "                serial_number += 1\n",
        "\n",
        "# Replace 'root_dir' with the directory you want to start from\n",
        "root_dir = '/Users/mskamran/Documents/Data Science/Raw'\n",
        "rename_images(root_dir)\n"
      ],
      "metadata": {
        "id": "nNIPmRM6tn0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trim the lebeling"
      ],
      "metadata": {
        "id": "tWpRLN6ux3TI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# n position to Position Trim\n",
        "\n",
        "import os\n",
        "\n",
        "def rename_images(root_dir):\n",
        "    for root, dirs, files in os.walk(root_dir):\n",
        "        serial_number = 1\n",
        "        for filename in files:\n",
        "            if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
        "                old_path = os.path.join(root, filename)\n",
        "                parts = filename.split('_')\n",
        "                new_filename = '_'.join(parts[7:13]) + f'_{serial_number}' + os.path.splitext(filename)[1]\n",
        "                new_path = os.path.join(root, new_filename)\n",
        "                os.rename(old_path, new_path)\n",
        "                print(\"Renamed:\", filename, \"->\", new_filename)\n",
        "                serial_number += 1\n",
        "\n",
        "# Replace 'root_dir' with the directory you want to start from\n",
        "root_dir = '/Users/mskamran/Documents/Data Science/All Raw Images With Image Lebel'\n",
        "rename_images(root_dir)"
      ],
      "metadata": {
        "id": "vTyPV0Lkx7BT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1st position delete\n",
        "\n",
        "import os\n",
        "\n",
        "def rename_images(root_dir):\n",
        "    for root, dirs, files in os.walk(root_dir):\n",
        "        for filename in files:\n",
        "            if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
        "                old_path = os.path.join(root, filename)\n",
        "                parts = filename.split('_')\n",
        "                new_filename = '_'.join(parts[1:])\n",
        "                new_path = os.path.join(root, new_filename)\n",
        "                os.rename(old_path, new_path)\n",
        "                print(\"Renamed:\", filename, \"->\", new_filename)\n",
        "\n",
        "# Replace 'root_dir' with the directory you want to start from\n",
        "root_dir = '/Users/mskamran/Documents/Data Science/All Raw Images With Image Lebel'\n",
        "rename_images(root_dir)\n"
      ],
      "metadata": {
        "id": "5hNKcY5D0Qv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Rename Code**"
      ],
      "metadata": {
        "id": "vz6wX1Me6pD2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add name in Front"
      ],
      "metadata": {
        "id": "td719p6864uF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Replace with your actual root path on your MacBook\n",
        "root_path = \"/Users/mskamran/Documents/Data Science/letters in different quality image/512 all letters old\"\n",
        "\n",
        "# Ensure destination folder exists\n",
        "os.makedirs(root_path, exist_ok=True)  # Create if it doesn't exist\n",
        "\n",
        "# Iterate through subdirectories in the root path\n",
        "for dirpath, dirnames, filenames in os.walk(root_path):\n",
        "    for filename in filenames:\n",
        "        # Check if file is a supported image\n",
        "        if filename.endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\")):\n",
        "            # Construct original and new file paths\n",
        "            source_path = os.path.join(dirpath, filename)\n",
        "            new_filename = f\"Kishoregonj_Shukhia Bazar_{filename}\"  # Add prefix to filename\n",
        "            new_path = os.path.join(dirpath, new_filename)\n",
        "\n",
        "            # Handle potential file conflicts (optional)\n",
        "            # ... (Implement your desired conflict handling here, e.g., overwrite, rename) ...\n",
        "\n",
        "            try:\n",
        "                # Rename the image in the same directory\n",
        "                os.rename(source_path, new_path)\n",
        "\n",
        "                print(f\"Renamed {filename} to {new_filename} in directory {dirpath}\")\n",
        "\n",
        "            except OSError as e:\n",
        "                print(f\"Error processing {filename}: {e}\")  # Handle potential errors\n",
        "\n",
        "print(\"Image renaming completed!\")\n"
      ],
      "metadata": {
        "id": "LldtyB0s6rge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Replace Class and Age"
      ],
      "metadata": {
        "id": "UUCf3hdN6-Y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def rename_images(root_path):\n",
        "    # Iterate through subdirectories in the root path\n",
        "    for dirpath, dirnames, filenames in os.walk(root_path):\n",
        "        for filename in filenames:\n",
        "            # Check if file is a supported image\n",
        "            if filename.endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\")):\n",
        "                # Split the filename into parts\n",
        "                parts = filename.split('_')\n",
        "\n",
        "                # Rename based on the specified criteria\n",
        "                if len(parts) >= 4:\n",
        "                    # Class renaming\n",
        "                    if parts[2].startswith('class'):\n",
        "                        new_class = f'C{int(parts[2][5:]):d}'\n",
        "                        parts[2] = new_class.lstrip('0')\n",
        "\n",
        "                    # Age renaming\n",
        "                    if parts[3].startswith('age'):\n",
        "                        new_age = f'A{int(parts[3][3:]):d}'\n",
        "                        parts[3] = new_age.lstrip('0')\n",
        "\n",
        "                    # Construct new filename\n",
        "                    new_filename = '_'.join(parts)\n",
        "\n",
        "                    # Construct original and new file paths\n",
        "                    source_path = os.path.join(dirpath, filename)\n",
        "                    new_path = os.path.join(dirpath, new_filename)\n",
        "\n",
        "                    # Rename the image\n",
        "                    os.rename(source_path, new_path)\n",
        "\n",
        "                    print(f\"Renamed {filename} to {new_filename} in directory {dirpath}\")\n",
        "\n",
        "# Replace with your actual root path\n",
        "root_path = \"/Users/mskamran/Documents/Data Science/letters in different quality image/512 all letters old\"\n",
        "\n",
        "# Rename the images\n",
        "rename_images(root_path)\n"
      ],
      "metadata": {
        "id": "wOUBUZE77KiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add Something In \"N\" Position"
      ],
      "metadata": {
        "id": "ndrX1NDO7Qty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Replace with your actual root path\n",
        "root_path = \"/Users/mskamran/Documents/Data Science/letters in different quality image/512 all letters old\"\n",
        "\n",
        "# Iterate through the files in the directory\n",
        "for filename in os.listdir(root_path):\n",
        "    # Split the filename into parts\n",
        "    parts = filename.split('_')\n",
        "\n",
        "    # Check if the filename has at least 4 parts\n",
        "    #if len(parts) >= 4:\n",
        "        # Insert 'n' at the 4th position\n",
        "        #parts.insert(3, 'N')\n",
        "\n",
        "    # Check if the filename has at least 6 parts\n",
        "    if len(parts) >= 6:\n",
        "        #Insert 'P1' at the 6th position\n",
        "        parts.insert(5, 'P1')\n",
        "\n",
        "        # Join the parts back into a filename\n",
        "        new_filename = '_'.join(parts)\n",
        "\n",
        "        # Rename the file\n",
        "        os.rename(os.path.join(root_path, filename), os.path.join(root_path, new_filename))\n",
        "        print(f\"Renamed {filename} to {new_filename}\")\n",
        "\n",
        "print(\"File renaming completed!\")\n"
      ],
      "metadata": {
        "id": "m1u1Mm1m7MnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add Seriaal Number in Last Position"
      ],
      "metadata": {
        "id": "xlsP8cuT7xEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Specify the directory path\n",
        "directory = \"/Users/mskamran/Documents/Data Science/letters in different quality image/512 all letters old\"\n",
        "\n",
        "# Initialize a counter for the serial number\n",
        "serial_number_counter = 1\n",
        "\n",
        "# Iterate through all files in the directory\n",
        "for filename in os.listdir(directory):\n",
        "    # Split the filename into parts using '_' as delimiter\n",
        "    parts = filename.split('_')\n",
        "\n",
        "    # Check if the filename has at least 7 parts\n",
        "    if len(parts) >= 7:\n",
        "        # Generate the serial number\n",
        "        serial_number = str(serial_number_counter)\n",
        "\n",
        "        # Insert the serial number at the 7th position\n",
        "        parts.insert(6, serial_number)\n",
        "\n",
        "        # Join the parts back together with '_' as delimiter\n",
        "        new_filename = '_'.join(parts)\n",
        "\n",
        "        # Rename the file\n",
        "        os.rename(os.path.join(directory, filename), os.path.join(directory, new_filename))\n",
        "        print(f\"Renamed {filename} to {new_filename}\")\n",
        "\n",
        "        # Increment the serial number counter\n",
        "        serial_number_counter += 1\n",
        "\n",
        "print(\"File renaming completed!\")\n"
      ],
      "metadata": {
        "id": "yUN8zm8h7XEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RESIZE IMAGE**"
      ],
      "metadata": {
        "id": "IpaCFKupxVFt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resized in the same folder"
      ],
      "metadata": {
        "id": "Qjo6dN3NuQeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def resize_images(root_dir, target_size=(5100, 7002)):\n",
        "    for root, dirs, files in os.walk(root_dir):\n",
        "        for filename in files:\n",
        "            if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
        "                image_path = os.path.join(root, filename)\n",
        "                with Image.open(image_path) as img:\n",
        "                    if img.size != target_size:\n",
        "                        resized_img = img.resize(target_size, Image.BICUBIC)\n",
        "                        resized_img.save(image_path)\n",
        "                        print(\"Resized:\", filename)\n",
        "                    else:\n",
        "                        print(\"Skipped (already resized):\", filename)\n",
        "\n",
        "# Replace 'root_dir' with the directory you want to start from\n",
        "root_dir = '/Users/mskamran/Documents/Data Science/Raw'\n",
        "resize_images(root_dir)\n"
      ],
      "metadata": {
        "id": "sh6ZQgJZt604"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resized in the Different Folder"
      ],
      "metadata": {
        "id": "ji6_DQ6zwdMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def resize_images(root_dir, target_dir, target_size=(5100, 7002)):\n",
        "    for root, dirs, files in os.walk(root_dir):\n",
        "        for filename in files:\n",
        "            if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
        "                image_path = os.path.join(root, filename)\n",
        "                with Image.open(image_path) as img:\n",
        "                    if img.size != target_size:\n",
        "                        resized_img = img.resize(target_size, Image.BICUBIC)\n",
        "                        # Construct the new path to save the resized image\n",
        "                        new_path = os.path.join(target_dir, filename)\n",
        "                        resized_img.save(new_path)\n",
        "                        print(\"Resized and saved to:\", new_path)\n",
        "                    else:\n",
        "                        print(\"Skipped (already resized):\", filename)\n",
        "\n",
        "# Replace 'root_dir' and 'target_dir' with the directories you want to start from and save to\n",
        "root_dir = '/Users/mskamran/Documents/Data Science/Raw'\n",
        "target_dir = '/Users/mskamran/Documents/Data Science/Resized'\n",
        "resize_images(root_dir, target_dir)\n"
      ],
      "metadata": {
        "id": "8dkahYh_wbcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert The Images into Lower Resulation"
      ],
      "metadata": {
        "id": "mxePML5mEP5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#convert the images into lower resulation\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def print_nested_folders(root_folder, output_folder):\n",
        "    for item in os.listdir(root_folder):\n",
        "        if os.path.isdir(os.path.join(root_folder, item)):\n",
        "            print_nested_folders(os.path.join(root_folder, item), output_folder)\n",
        "        else:\n",
        "            if item.endswith(\".jpg\"):\n",
        "                print(\"Resizing image:\", os.path.join(root_folder, item))\n",
        "                image = Image.open(os.path.join(root_folder, item))\n",
        "                resized_image = image.resize((28, 28))\n",
        "                output_path = os.path.join(output_folder, item)\n",
        "                resized_image.save(output_path)\n",
        "\n",
        "# Example usage\n",
        "root_folder = \"/content/drive/MyDrive/OCR Thesis/Kishoregonj/letters/\"\n",
        "output_folder = \"/content/drive/MyDrive/OCR Thesis/Kishoregonj/letters low resu\"\n",
        "print_nested_folders(root_folder, output_folder)\n"
      ],
      "metadata": {
        "id": "FgLXUlw_EOzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Copy many folder to one**"
      ],
      "metadata": {
        "id": "epVlR0IvxApk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from shutil import copy2\n",
        "\n",
        "# Replace with your actual root path on your MacBook\n",
        "root_path = \"/Users/mskamran/Documents/Data Science/Raw\"\n",
        "\n",
        "# Replace with your preferred destination folder on your MacBook\n",
        "destination_folder = \"/Users/mskamran/Documents/Data Science/All Raw Images With Image Lebel\"\n",
        "\n",
        "# Ensure destination folder exists\n",
        "os.makedirs(destination_folder, exist_ok=True)  # Create if it doesn't exist\n",
        "\n",
        "# Iterate through subdirectories in the root path\n",
        "for dirpath, dirnames, filenames in os.walk(root_path):\n",
        "    for filename in filenames:\n",
        "        # Check if file is a supported image\n",
        "        if filename.endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\")):\n",
        "            # Construct original and destination file paths\n",
        "            source_path = os.path.join(dirpath, filename)\n",
        "            dest_path = os.path.join(destination_folder, filename)\n",
        "\n",
        "            # Handle potential file conflicts (optional)\n",
        "            # ... (Implement your desired conflict handling here, e.g., overwrite, rename) ...\n",
        "\n",
        "            try:\n",
        "                # Copy the image to the destination folder\n",
        "                copy2(source_path, dest_path)\n",
        "                print(f\"Copied {filename} to {dest_path}\")\n",
        "\n",
        "            except OSError as e:\n",
        "                print(f\"Error copying {filename}: {e}\")  # Handle potential errors\n",
        "\n",
        "print(\"Image copying completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWKTX6pyxCf-",
        "outputId": "761faa70-cd94-468e-8196-9f1565c3f249"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image copying completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Many Folder to one Folder MOVING Code"
      ],
      "metadata": {
        "id": "Owvlg5ue9Ivr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Replace with your actual root path on your MacBook\n",
        "root_path = \"/Users/mskamran/Documents/Data Science/letters in different quality image/512 all letters old\"\n",
        "\n",
        "# Replace with your preferred destination folder on your MacBook\n",
        "destination_folder = \"/Users/mskamran/Documents/Data Science/ALL Letters old and new\"\n",
        "\n",
        "# Ensure destination folder exists\n",
        "os.makedirs(destination_folder, exist_ok=True)  # Create if it doesn't exist\n",
        "\n",
        "# Iterate through subdirectories in the root path\n",
        "for dirpath, dirnames, filenames in os.walk(root_path):\n",
        "    for filename in filenames:\n",
        "        # Check if file is a supported image\n",
        "        if filename.endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\")):\n",
        "            # Construct original and destination file paths\n",
        "            source_path = os.path.join(dirpath, filename)\n",
        "            dest_path = os.path.join(destination_folder, filename)\n",
        "\n",
        "            # Handle potential file conflicts (optional)\n",
        "            # ... (Implement your desired conflict handling here, e.g., overwrite, rename) ...\n",
        "\n",
        "            try:\n",
        "                # Copy the image to the destination folder\n",
        "                shutil.copy2(source_path, dest_path)\n",
        "\n",
        "                print(f\"Copied {filename} to {dest_path}\")\n",
        "\n",
        "            except OSError as e:\n",
        "                print(f\"Error processing {filename}: {e}\")  # Handle potential errors\n",
        "\n",
        "print(\"Image copying completed!\")"
      ],
      "metadata": {
        "id": "wAWuuUHd9V-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Copy page 1 or 2**"
      ],
      "metadata": {
        "id": "6iDgATO21Rg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from shutil import copy2\n",
        "\n",
        "def rename_and_copy_images(root_dir, destination_folder):\n",
        "    for root, dirs, files in os.walk(root_dir):\n",
        "        serial_number = 1\n",
        "        for filename in files:\n",
        "            if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
        "                old_path = os.path.join(root, filename)\n",
        "                parts = filename.split('_')\n",
        "                if parts[5] == \"P1\":\n",
        "                    # If \"P1\" is present in the 5th position, copy the image to the destination folder\n",
        "                    copy_path = os.path.join(destination_folder, filename)\n",
        "                    copy2(old_path, copy_path)\n",
        "                    print(\"Copied:\", filename, \"->\", copy_path)\n",
        "\n",
        "\n",
        "# Replace 'root_dir' with the directory you want to start from\n",
        "root_dir = '/Users/mskamran/Documents/Data Science/All Raw Images With Image Lebel'\n",
        "\n",
        "# Replace 'destination_folder' with the path to the folder where you want to copy the images\n",
        "destination_folder = '/Users/mskamran/Documents/Data Science/Page2 With Lebel'\n",
        "\n",
        "rename_and_copy_images(root_dir, destination_folder)\n"
      ],
      "metadata": {
        "id": "7zHBx4s41QWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Edit Images (grayscale > Threshold > Noise reduction > Increase contrast ) test**"
      ],
      "metadata": {
        "id": "2DxEPB301xC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For Normal Scanned image"
      ],
      "metadata": {
        "id": "53d0ZRU12KeS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## USABLE BT NOT USE IN NEW **DATA**"
      ],
      "metadata": {
        "id": "VnHkvS_T4alN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#remove dots and save auto(threshold > grayscale > identify dots > binary image >  Noise reduction > Thresholding again)\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "\n",
        "def remove_dots_and_threshold(img_path, output_path):\n",
        "    # Read the image\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Threshold the image to identify dots\n",
        "    _, thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # Find contours in the binary image\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Loop through each contour\n",
        "    for contour in contours:\n",
        "        # If the contour area is small (indicating it's a dot), fill it with white color\n",
        "        if cv2.contourArea(contour) < 200:\n",
        "            cv2.drawContours(gray, [contour], 0, (255,255,255), -1)\n",
        "\n",
        "    # Noise reduction using morphological opening\n",
        "    #kernel = np.ones((math.ceil(.5), math.ceil(.5)), np.uint8)\n",
        "    kernel = np.ones((1, 1), np.uint8)\n",
        "    opened = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    # Thresholding again after removing noise\n",
        "    _, result = cv2.threshold(opened, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Save the result\n",
        "    cv2.imwrite(output_path, result)\n",
        "\n",
        "# Source directory containing images and destination directory to save processed images\n",
        "source_dir = '/Users/mskamran/Documents/Data Science/Page1 After pre proess'\n",
        "dest_dir = '/Users/mskamran/Documents/Data Science/res'\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "if not os.path.exists(dest_dir):\n",
        "    os.makedirs(dest_dir)\n",
        "\n",
        "# Iterate through each image in the source directory\n",
        "for filename in os.listdir(source_dir):\n",
        "    # Check if the file is an image (You can add more formats if needed)\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg'):\n",
        "        img_path = os.path.join(source_dir, filename)\n",
        "        output_path = os.path.join(dest_dir, filename)\n",
        "        remove_dots_and_threshold(img_path, output_path)\n"
      ],
      "metadata": {
        "id": "qa8P6KtB4SAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# USED IN NEW DATA"
      ],
      "metadata": {
        "id": "v2YsUALZ4fqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def preprocess_image(img, threshold_value, noise_reduction_kernel_size, contrast_value):\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Threshold the image\n",
        "    _, thresh = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Noise reduction using morphological opening\n",
        "    kernel = np.ones((noise_reduction_kernel_size, noise_reduction_kernel_size), np.uint8)\n",
        "    opened = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    # Increase contrast\n",
        "    adjusted = cv2.convertScaleAbs(opened, alpha=contrast_value, beta=0)\n",
        "\n",
        "    return adjusted\n",
        "\n",
        "def process_image(img_path, output_path, threshold_value=127, noise_reduction_kernel_size=1, contrast_value=1.0):\n",
        "    # Read the image\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "    # Preprocess the image\n",
        "    processed_img = preprocess_image(img, threshold_value, noise_reduction_kernel_size, contrast_value)\n",
        "\n",
        "    # Save the result\n",
        "    cv2.imwrite(output_path, processed_img)\n",
        "\n",
        "# Source directory containing images and destination directory to save processed images\n",
        "source_dir = '/Users/mskamran/Documents/Data Science/Page1 With Lebel'\n",
        "dest_dir = '/Users/mskamran/Documents/Data Science/Page1 After pre proess'\n",
        "\n",
        "# Define parameters\n",
        "threshold_value = 200\n",
        "noise_reduction_kernel_size = 1\n",
        "contrast_value = 1.0\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "if not os.path.exists(dest_dir):\n",
        "    os.makedirs(dest_dir)\n",
        "\n",
        "# Iterate through each image in the source directory\n",
        "for filename in os.listdir(source_dir):\n",
        "    # Check if the file is an image (You can add more formats if needed)\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg'):\n",
        "        img_path = os.path.join(source_dir, filename)\n",
        "        output_path = os.path.join(dest_dir, filename)\n",
        "        process_image(img_path, output_path, threshold_value, noise_reduction_kernel_size, contrast_value)\n"
      ],
      "metadata": {
        "id": "hHojFm8t1-IM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dot Remove (Identify Dots > Binary image > Thresholding again)"
      ],
      "metadata": {
        "id": "ClMacRov2xK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#remove dots and save auto(threshold > grayscale > identify dots > binary image >  Noise reduction > Thresholding again)\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def remove_dots_and_threshold(img_path, output_path):\n",
        "    # Read the image\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Threshold the image to identify dots\n",
        "    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # Find contours in the binary image\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Loop through each contour\n",
        "    for contour in contours:\n",
        "        # If the contour area is small (indicating it's a dot), fill it with white color\n",
        "        if cv2.contourArea(contour) < 200:\n",
        "            cv2.drawContours(gray, [contour], 0, (255,255,255), -1)\n",
        "\n",
        "    # Noise reduction using morphological opening\n",
        "    kernel = np.ones((1, 1), np.uint8)\n",
        "    opened = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    # Thresholding again after removing noise\n",
        "    _, result = cv2.threshold(opened, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Save the result\n",
        "    cv2.imwrite(output_path, result)\n",
        "\n",
        "# Source directory containing images and destination directory to save processed images\n",
        "source_dir = '/Users/mskamran/Documents/Data Science/Page1 After pre proess'\n",
        "dest_dir = '/Users/mskamran/Documents/Data Science/P1 dot remove'\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "if not os.path.exists(dest_dir):\n",
        "    os.makedirs(dest_dir)\n",
        "\n",
        "# Iterate through each image in the source directory\n",
        "for filename in os.listdir(source_dir):\n",
        "    # Check if the file is an image (You can add more formats if needed)\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg'):\n",
        "        img_path = os.path.join(source_dir, filename)\n",
        "        output_path = os.path.join(dest_dir, filename)\n",
        "        remove_dots_and_threshold(img_path, output_path)\n"
      ],
      "metadata": {
        "id": "h72mQkze2zDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For Mobile Image"
      ],
      "metadata": {
        "id": "1qylgZa73kEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def preprocess_image(img, threshold_value, noise_reduction_kernel_size, contrast_value):\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Threshold the image\n",
        "    _, thresh = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Noise reduction using morphological opening\n",
        "    kernel = np.ones((noise_reduction_kernel_size, noise_reduction_kernel_size), np.uint8)\n",
        "    opened = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    # Increase contrast\n",
        "    adjusted = cv2.convertScaleAbs(opened, alpha=contrast_value, beta=0)\n",
        "\n",
        "    return adjusted\n",
        "\n",
        "def sharpen_image(img):\n",
        "    # Define the sharpening kernel\n",
        "    kernel_sharpening = np.array([[-1,-1,-1],\n",
        "                                  [-1, 9,-1],\n",
        "                                  [-1,-1,-1]])\n",
        "\n",
        "    # Apply the sharpening kernel\n",
        "    sharpened_img = cv2.filter2D(img, -1, kernel_sharpening)\n",
        "    return sharpened_img\n",
        "\n",
        "def process_image(img_path, output_path, threshold_value=127, noise_reduction_kernel_size=1, contrast_value=1.0):\n",
        "    # Read the image\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "    # Preprocess the image\n",
        "    processed_img = preprocess_image(img, threshold_value, noise_reduction_kernel_size, contrast_value)\n",
        "\n",
        "    # Sharpen the processed image\n",
        "    sharpened_img = sharpen_image(processed_img)\n",
        "\n",
        "    # Save the result\n",
        "    cv2.imwrite(output_path, sharpened_img)\n",
        "\n",
        "# Source directory containing images and destination directory to save processed images\n",
        "source_dir = '/Users/mskamran/Documents/Data Science/need to edit different'\n",
        "dest_dir = '/Users/mskamran/Documents/Data Science/Page1 After pre proess'\n",
        "\n",
        "# Define parameters\n",
        "threshold_value = 150\n",
        "noise_reduction_kernel_size = 1\n",
        "contrast_value = 1.0\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "if not os.path.exists(dest_dir):\n",
        "    os.makedirs(dest_dir)\n",
        "\n",
        "# Iterate through each image in the source directory\n",
        "for filename in os.listdir(source_dir):\n",
        "    # Check if the file is an image (You can add more formats if needed)\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg'):\n",
        "        img_path = os.path.join(source_dir, filename)\n",
        "        output_path = os.path.join(dest_dir, filename)\n",
        "        process_image(img_path, output_path, threshold_value, noise_reduction_kernel_size, contrast_value)\n"
      ],
      "metadata": {
        "id": "alLFyOcy3myG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove dots and save auto(threshold > grayscale > identify dots > binary image >  Noise reduction > Thresholding again)\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def remove_dots_and_threshold(img_path, output_path):\n",
        "    # Read the image\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Threshold the image to identify dots\n",
        "    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # Find contours in the binary image\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Loop through each contour\n",
        "    for contour in contours:\n",
        "        # If the contour area is small (indicating it's a dot), fill it with white color\n",
        "        if cv2.contourArea(contour) < 200:\n",
        "            cv2.drawContours(gray, [contour], 0, (255,255,255), -1)\n",
        "\n",
        "    # Noise reduction using morphological opening\n",
        "    kernel = np.ones((1, 1), np.uint8)\n",
        "    opened = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    # Thresholding again after removing noise\n",
        "    _, result = cv2.threshold(opened, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Save the result\n",
        "    cv2.imwrite(output_path, result)\n",
        "\n",
        "# Source directory containing images and destination directory to save processed images\n",
        "source_dir = '/Users/mskamran/Documents/Data Science/Page1 After pre proess'\n",
        "dest_dir = '/Users/mskamran/Documents/Data Science/res'\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "if not os.path.exists(dest_dir):\n",
        "    os.makedirs(dest_dir)\n",
        "\n",
        "# Iterate through each image in the source directory\n",
        "for filename in os.listdir(source_dir):\n",
        "    # Check if the file is an image (You can add more formats if needed)\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg'):\n",
        "        img_path = os.path.join(source_dir, filename)\n",
        "        output_path = os.path.join(dest_dir, filename)\n",
        "        remove_dots_and_threshold(img_path, output_path)\n"
      ],
      "metadata": {
        "id": "AeK0aQ5n3uxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Crop Letters Old Data**"
      ],
      "metadata": {
        "id": "NKRSzqbp9li8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#crop the images\n",
        "\n",
        "import os, glob\n",
        "from PIL import Image\n",
        "\n",
        "#  array of all letters\n",
        "bangla_alphabets = [\n",
        "    'অ', 'ঋ', 'খ', 'জ', 'ঢ', 'ন', 'য', 'হ', 'ো', 'ে', 'ূ', '৪', 'ক্ষ', 'চ্ছ', 'স্থ', 'শ্র',\n",
        "    'আ', 'এ', 'গ', 'ঝ', 'ণ', 'প', 'র', 'ড়', 'ঁ', 'ৈ', 'ৃ', '৫', 'ঞ্চ', 'ন্ত', 'হ্ণ', 'জ্ঞ',\n",
        "    'ই', 'ঐ', 'ঘ', 'ঞ', 'ত', 'ফ', 'ল', 'ঢ়', 'া', 'ো', '০', '৬', 'ঞ্জ', 'ন্ড', 'হ্ন', 'দ্ব',\n",
        "    'ঈ', 'ও', 'ঙ', 'ট', 'থ', 'ব', 'শ', 'য়', 'ি', 'ৌ', '১', '৭', 'ণ্ট', 'স্ত', 'ক্ল', 'ব্ল',\n",
        "    'উ', 'ঔ', 'চ', 'ঠ', 'দ', 'ভ', 'ষ', 'ৎ', 'ী', '‍্য', '২', '৮', 'ক্ত', 'স্ট', 'ন্দ', 'ম্ন',\n",
        "    'ঊ', 'ক', 'ছ', 'ড', 'ধ', 'ম', 'স', 'ং', 'ু', '্র', '৩', '৯', 'চ্চ', 'স্ত', 'ন্ন'\n",
        "]\n",
        "\n",
        "# coordinate of each image\n",
        "sizes=[(100,0,270,140),  (100,140,270,270),  (100,270,270,400),  (100,420,270,540),  (100,550,270,670),  (100,680,270,820),  (100,820,270,960),  (100,960,270,1100),  (100,1100,270,1250),  (100,1240,270,1380),  (100,1370,270,1520), (100,1510,270,1660),(100,1640,270,1800),(100,1790,270,1930),(100,1930,270,2070),(100,2070,270,2190),\n",
        "       (410,0,560,140),  (410,140,560,270),  (410,270,560,400),  (410,420,560,540),  (410,550,560,670),  (410,680,560,820),  (410,820,560,960),  (410,960,560,1100),  (410,1100,560,1250),  (410,1240,560,1380),  (410,1370,560,1520),(410,1510,560,1660),(410,1640,560,1800),(410,1790,560,1930),(410,1930,560,2070),(410,2070,560,2190),\n",
        "       (700,0,830,140),  (700,140,830,270),  (700,270,830,400),  (700,420,830,540),  (700,550,830,670),  (700,680,830,820),  (700,820,830,960),  (700,960,830,1100),  (700,1100,830,1250),  (700,1240,830,1380),  (700,1370,830,1520),(700,1510,830,1660),(700,1640,830,1800),(700,1790,830,1930),(700,1930,830,2070),(700,2070,830,2190),\n",
        "       (980,0,1130,140), (980,140,1130,270), (980,270,1130,400), (980,420,1130,540), (980,550,1130,670), (980,680,1130,820), (980,820,1130,960), (980,960,1130,1100), (980,1100,1130,1250), (980,1240,1130,1380), (980,1370,1130,1520),(980,1510,1130,1660),(980,1640,1130,1800),(980,1790,1130,1930),(980,1930,1130,2070),(980,2070,1130,2190),\n",
        "       (1250,0,1420,140),(1250,140,1420,270),(1250,270,1420,400),(1250,420,1420,540),(1250,550,1420,670),(1250,680,1420,820),(1250,820,1420,960),(1250,960,1420,1100),(1250,1100,1420,1250),(1250,1240,1420,1380),(1250,1370,1420,1520),(1250,1510,1420,1660),(1250,1640,1420,1800),(1250,1790,1420,1930),(1250,1930,1420,2070),(1250,2070,1420,2190),\n",
        "       (1550,0,1700,140),(1550,140,1700,270),(1550,270,1700,400),(1550,420,1700,540),(1550,550,1700,670),(1550,680,1700,820),(1550,820,1700,960),(1550,960,1700,1100),(1550,1100,1700,1250),(1550,1240,1700,1380),(1550,1370,1700,1520),(1550,1510,1700,1660),(1550,1640,1700,1800),(1550,1790,1700,1930),(1550,1930,1700,2070)\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# Define the base directory where your images are located\n",
        "base_dir = \"/Users/mskamran/Downloads/ML Class/Image without dotted lines/\"\n",
        "\n",
        "# Define the class and age directories\n",
        "class_dir = \"Class 10\"\n",
        "age_dir = \"Class 10 age 15\"\n",
        "\n",
        "# Define the filename pattern\n",
        "filename_pattern = \"class 10 age 15_{}.jpg\"\n",
        "\n",
        "# Define the output directory for saving cropped images\n",
        "output_dir = \"/Users/mskamran/Downloads/ML Class/LettersClean/\"\n",
        "\n",
        "# Initialize index for Bangla alphabets and serial number\n",
        "a = 0\n",
        "serial_number = 1\n",
        "\n",
        "# Loop through the range of serial numbers\n",
        "for serial in range(1, 40):  # Adjust the range as needed\n",
        "    # Construct the full file path\n",
        "    filepath = os.path.join(base_dir, class_dir, age_dir, filename_pattern.format(serial))\n",
        "\n",
        "    # Check if the file exists\n",
        "    if os.path.exists(filepath):\n",
        "        img = Image.open(filepath)\n",
        "        for i in sizes:\n",
        "            new = Image.new('RGB', (28, 28), color='white')\n",
        "            imm = img.crop(box=(i))\n",
        "            imm1 = imm.resize((28, 28))\n",
        "            new.paste(imm1, (0, 0))\n",
        "\n",
        "            # Get the current Bangla alphabet based on index\n",
        "            current_alphabet = bangla_alphabets[a % len(bangla_alphabets)]\n",
        "\n",
        "            # Construct the save path\n",
        "            save_path = os.path.join(output_dir, class_dir, age_dir, f\"clas10_age15_{current_alphabet}_{serial_number}.jpg\")\n",
        "\n",
        "            # Save the image\n",
        "            new.save(save_path)\n",
        "\n",
        "            # Increment the indices\n",
        "            a += 1\n",
        "            serial_number += 1\n"
      ],
      "metadata": {
        "id": "qBK0R9xn9qC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Crop Letters For New Data**"
      ],
      "metadata": {
        "id": "QvCfy8de9rgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# array of all letters\n",
        "bangla_alphabets = [\n",
        "    'অ', 'আ', 'ই', 'ঈ', 'উ', 'ঊ',\n",
        "    'ঋ', 'এ', 'ঐ', 'ও', 'ঔ', 'ক',\n",
        "    'খ', 'গ', 'ঘ', 'ঙ', 'চ', 'ছ',\n",
        "    'জ', 'ঝ', 'ঞ', 'ট', 'ঠ', 'ড',\n",
        "    'ঢ', 'ণ', 'ত', 'থ', 'দ', 'ধ',\n",
        "    'ন', 'প', 'ফ', 'ব', 'ভ', 'ম',\n",
        "    'য', 'র', 'ল', 'শ', 'ষ', 'স',\n",
        "    'হ', 'ড়', 'ঢ়', 'য়', 'ৎ', 'ং',\n",
        "    'ো', 'ঁ', 'া', 'ি', 'ী', 'ু',\n",
        "    'ে', 'ৈ', 'ৌ', '‍্য', '্র', 'ৃ',\n",
        "    'ূ', 'ঃ', '১', '২', '৩', '৪',\n",
        "    '৫', '৬', '৭', '৮', '৯', '০',\n",
        "    'ক্ষ', 'ঞ্চ', 'ঞ্জ', 'ণ্ট', 'ক্ত', 'ন্ন',\n",
        "    'চ্ছ', 'ন্ত', 'ন্ড', 'স্ত', 'স্ট', 'জ্জ',\n",
        "    'স্থ', 'হ্ণ', 'হ্ন', 'ক্ল', 'ন্দ', 'ত্ম',\n",
        "    'শ্র', 'জ্ঞ', 'দ্ব', 'ব্ল', 'ম্ন', 'দ্ধ'\n",
        "]\n",
        "\n",
        "# coordinate of each image\n",
        "sizes = [\n",
        "    #'অ', 'আ', 'ই', 'ঈ', 'উ', 'ঊ',\n",
        "    (780, 1150, 1160, 1440), (1480, 1150, 1860, 1440), (2180, 1150, 2560, 1440), (2880, 1150, 3280, 1440), (3580, 1150, 4000, 1440), (4350, 1150, 4740, 1440),\n",
        "    #'ঋ', 'এ', 'ঐ', 'ও', 'ঔ', 'ক',\n",
        "    (780, 1420, 1160, 1730), (1480, 1420, 1860, 1730), (2180, 1420, 2560, 1730), (2880, 1420, 3280, 1730), (3580, 1420, 4000, 1730), (4350, 1420, 4740, 1730),\n",
        "    #'খ', 'গ', 'ঘ', 'ঙ', 'চ', 'ছ',\n",
        "    (780, 1740, 1160, 2070), (1480, 1740, 1860, 2070), (2180, 1740, 2560, 2070), (2880, 1740, 3280, 2070), (3580, 1740, 4000, 2070), (4350, 1740, 4740, 2070),\n",
        "    #'জ', 'ঝ', 'ঞ', 'ট', 'ঠ', 'ড',\n",
        "    (780, 2080, 1160, 2400), (1480, 2080, 1860, 2400), (2180, 2080, 2560, 2400), (2880, 2080, 3280, 2400), (3580, 2080, 4000, 2400), (4350, 2080, 4740, 2400),\n",
        "    #'ঢ', 'ণ', 'ত', 'থ', 'দ', 'ধ',\n",
        "    (780, 2410, 1160, 2735), (1480, 2410, 1860, 2735), (2180, 2410, 2560, 2735), (2880, 2410, 3280, 2735), (3580, 2410, 4000, 2735), (4350, 2410, 4740, 2735),\n",
        "    #'ন', 'প', 'ফ', 'ব', 'ভ', 'ম',\n",
        "    (780, 2750, 1160, 3060), (1480, 2750, 1860, 3060), (2180, 2750, 2560, 3060), (2880, 2750, 3280, 3060), (3580, 2750, 4000, 3060), (4350, 2750, 4740, 3060),\n",
        "    # 'য', 'র', 'ল', 'শ', 'ষ', 'স',\n",
        "    (780, 3060, 1160, 3390), (1480, 3060, 1860, 3390), (2180, 3060, 2560, 3390), (2880, 3060, 3280, 3390), (3580, 3060, 4000, 3390), (4350, 3060, 4740, 3390),\n",
        "    #'হ', 'ড়', 'ঢ়', 'য়', 'ৎ', 'ং',\n",
        "    (780, 3390, 1160, 3735), (1480, 3390, 1860, 3735), (2180, 3390, 2560, 3735), (2880, 3390, 3280, 3735), (3580, 3390, 4000, 3735), (4350, 3390, 4740, 3735),\n",
        "    #'ো', 'ঁ', 'া', 'ি', 'ী', 'ু',\n",
        "    (780, 3735, 1160, 4060), (1480, 3735, 1860, 4060), (2180, 3735, 2560, 4060), (2880, 3735, 3280, 4060), (3580, 3735, 4000, 4060), (4350, 3735, 4740, 4060),\n",
        "    #'ে', 'ৈ', 'ৌ', '‍্য', '্র', 'ৃ',\n",
        "    (780, 4060, 1160, 4390), (1480, 4060, 1860, 4390), (2180, 4060, 2560, 4390), (2880, 4060, 3280, 4390), (3580, 4060, 4000, 4390), (4350, 4060, 4740, 4390),\n",
        "    #'ূ', 'ঃ', '১', '২', '৩', '৪',\n",
        "    (780, 4390, 1160, 4730), (1480, 4390, 1860, 4730), (2180, 4390, 2560, 4730), (2880, 4390, 3280, 4730), (3580, 4390, 4000, 4730), (4350, 4390, 4740, 4730),\n",
        "    #'৫', '৬', '৭', '৮', '৯', '০',\n",
        "    (780, 4730, 1160, 5060), (1480, 4730, 1860, 4730), (2180, 4730, 2560, 4730), (2880, 4730, 3280, 4730), (3580, 4730, 4000, 4730), (4350, 4730, 4740, 4730),\n",
        "    #'ক্ষ', 'ঞ্চ', 'ঞ্জ', 'ণ্ট', 'ক্ত', 'ন্ন',\n",
        "    (780, 5060, 1160, 5400), (1480, 5060, 1860, 5400), (2180, 5060, 2560, 5400), (2880, 5060, 3280, 5400), (3580, 5060, 4000, 5400), (4350, 5060, 4740, 5400),\n",
        "    #'চ্ছ', 'ন্ত', 'ন্ড', 'স্ত', 'স্ট', 'জ্জ',\n",
        "    (780, 5400, 1160, 5730), (1480, 5400, 1860, 5730), (2180, 5400, 2560, 5730), (2880, 5400, 3280, 5730), (3580, 5400, 4000, 5730), (4350, 5400, 4740, 5730),\n",
        "    #'স্থ', 'হ্ণ', 'হ্ন', 'ক্ল', 'ন্দ', 'ত্ম',\n",
        "    (780, 5730, 1160, 6070), (1480, 5730, 1860, 6070), (2180, 5730, 2560, 6070), (2880, 5730, 3280, 6070), (3580, 5730, 4000, 6070), (4350, 5730, 4740, 6070),\n",
        "    #'শ্র', 'জ্ঞ', 'দ্ব', 'ব্ল', 'ম্ন', 'দ্ধ'\n",
        "    (780, 6055, 1160, 6400), (1480, 6055, 1860, 6400), (2180, 6055, 2560, 6400), (2880, 6055, 3280, 6400), (3580, 6055, 4000, 6400), (4350, 6055, 4740, 6400),\n",
        "\n",
        "         ]\n",
        "\n",
        "\n",
        "# White background size\n",
        "background_size = (512, 512)\n",
        "\n",
        "# Iterate through each file in the source directory\n",
        "source_dir = '/Users/mskamran/Documents/Data Science/Page1 after preprocess dor remove'\n",
        "destination_dir = '/Users/mskamran/Documents/Data Science/Crop Letters All'\n",
        "\n",
        "# Create destination directory if it doesn't exist\n",
        "if not os.path.exists(destination_dir):\n",
        "    os.makedirs(destination_dir)\n",
        "\n",
        "for filename in os.listdir(source_dir):\n",
        "    # Check if the file is an image\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg'):\n",
        "        # Read the image\n",
        "        img = Image.open(os.path.join(source_dir, filename))\n",
        "\n",
        "        # Iterate through each cropping size and save the cropped images\n",
        "        for idx, size in enumerate(sizes):\n",
        "            # Crop the image according to the size\n",
        "            cropped_img = img.crop(size)\n",
        "\n",
        "            # Create a new white background image\n",
        "            new = Image.new('RGB', background_size, color='white')\n",
        "\n",
        "            # Calculate position to paste the cropped image in the center\n",
        "            x_offset = (background_size[0] - cropped_img.size[0]) // 2\n",
        "            y_offset = (background_size[1] - cropped_img.size[1]) // 2\n",
        "\n",
        "            # Paste the cropped image onto the new background\n",
        "            new.paste(cropped_img, (x_offset, y_offset))\n",
        "\n",
        "            # Split the filename and extension\n",
        "            filename_parts = filename.split('.')\n",
        "            if len(filename_parts) > 1:\n",
        "                filename_without_extension = '.'.join(filename_parts[:-1])\n",
        "                file_extension = filename_parts[-1]\n",
        "            else:\n",
        "                filename_without_extension = filename\n",
        "                file_extension = 'jpg'  # Set a default extension if none is found\n",
        "\n",
        "            # Construct the new filename with the original image name and the corresponding alphabet\n",
        "            new_filename = f\"{filename_without_extension}_{bangla_alphabets[idx]}.{file_extension}\"\n",
        "\n",
        "            # Save the image to the destination directory\n",
        "            new.save(os.path.join(destination_dir, new_filename))\n"
      ],
      "metadata": {
        "id": "e1zKfIFW90Mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Identify White Image if any and Move"
      ],
      "metadata": {
        "id": "5odomQbC98ex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "\n",
        "# Source directory\n",
        "source_dir = '/Users/mskamran/Documents/Data Science/Page1 after preprocess dor remove'\n",
        "\n",
        "# Destination directory for fully white images\n",
        "white_images_dir = '/Users/mskamran/Documents/Data Science/Fully White Images'\n",
        "\n",
        "# Create destination directory if it doesn't exist\n",
        "if not os.path.exists(white_images_dir):\n",
        "    os.makedirs(white_images_dir)\n",
        "\n",
        "# Function to check if an image is fully white\n",
        "def is_fully_white(image):\n",
        "    # Convert image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Calculate the mean pixel value\n",
        "    mean_pixel_value = cv2.mean(gray)[0]\n",
        "\n",
        "    # If mean pixel value is close to 255 (white), consider it fully white\n",
        "    return mean_pixel_value > 250\n",
        "\n",
        "# Iterate through each file in the source directory\n",
        "for filename in os.listdir(source_dir):\n",
        "    # Check if the file is an image\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg'):\n",
        "        # Read the image\n",
        "        img = cv2.imread(os.path.join(source_dir, filename))\n",
        "\n",
        "        # Check if the image is fully white\n",
        "        if is_fully_white(img):\n",
        "            # Move the fully white image to the destination directory\n",
        "            shutil.move(os.path.join(source_dir, filename), os.path.join(white_images_dir, filename))\n",
        "\n",
        "print(\"Fully white image detection and moving completed.\")\n"
      ],
      "metadata": {
        "id": "d94blt4E-DNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Just Noise Reduction"
      ],
      "metadata": {
        "id": "mogRNTZ2-Eug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Source and destination directories\n",
        "source_dir = '/Users/mskamran/Documents/Data Science/Page1 after preprocess dor remove'\n",
        "destination_dir = '/Users/mskamran/Documents/Data Science/Crop Letters All'\n",
        "\n",
        "# Create destination directory if it doesn't exist\n",
        "if not os.path.exists(destination_dir):\n",
        "    os.makedirs(destination_dir)\n",
        "\n",
        "# Function to remove noise from an image\n",
        "def remove_noise(image):\n",
        "    # Convert image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Threshold the image to create a binary mask\n",
        "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "\n",
        "    # Perform morphological operations to remove small noise\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    cleaned = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "\n",
        "    return cleaned\n",
        "\n",
        "# Iterate through each file in the source directory\n",
        "for filename in os.listdir(source_dir):\n",
        "    # Check if the file is an image\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg'):\n",
        "        # Read the image\n",
        "        img = cv2.imread(os.path.join(source_dir, filename))\n",
        "\n",
        "        # Remove noise from the image\n",
        "        cleaned_img = remove_noise(img)\n",
        "\n",
        "        # Save the cleaned image to the destination directory\n",
        "        cv2.imwrite(os.path.join(destination_dir, filename), cleaned_img)\n",
        "\n",
        "print(\"Noise removal completed.\")\n"
      ],
      "metadata": {
        "id": "6er0w9gN96yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Move and Find Specific Image**"
      ],
      "metadata": {
        "id": "fVPB9IJL371_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "source_dir = '/Users/mskamran/Documents/Data Science/Page1 With Lebel'\n",
        "destination_dir = '/Users/mskamran/Documents/Data Science/need to edit different'\n",
        "school_name = \"Rajshashi Court Academy School RCAS\"\n",
        "exclude_value = \"C8\"\n",
        "\n",
        "# Create destination directory if it doesn't exist\n",
        "if not os.path.exists(destination_dir):\n",
        "    os.makedirs(destination_dir)\n",
        "\n",
        "# Iterate through each file in the source directory\n",
        "for filename in os.listdir(source_dir):\n",
        "    # Split the filename by underscore\n",
        "    parts = filename.split('_')\n",
        "\n",
        "    # Check if the filename has at least 3 parts and the 2nd part matches the school name\n",
        "    if len(parts) >= 3 and parts[1] == school_name:\n",
        "        # Check if the 3rd part is not equal to exclude_value\n",
        "        if parts[2] != exclude_value:\n",
        "            # Construct source and destination paths\n",
        "            src_path = os.path.join(source_dir, filename)\n",
        "            dst_path = os.path.join(destination_dir, filename)\n",
        "\n",
        "            # Move the file to the destination directory\n",
        "            shutil.move(src_path, dst_path)\n",
        "            print(f\"Moved {filename} to {destination_dir}\")\n"
      ],
      "metadata": {
        "id": "zIQs4Qud4DTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find Specific Letters and In a Folder And Count"
      ],
      "metadata": {
        "id": "4Htg_OfN-drk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Replace with your source folder containing the images\n",
        "source_folder = \"/Users/mskamran/Documents/Data Science/letters in different quality image/28*28\"\n",
        "\n",
        "# List files in the source folder\n",
        "file_list = os.listdir(source_folder)\n",
        "\n",
        "# Initialize a counter for filenames meeting the condition\n",
        "count = 0\n",
        "\n",
        "# Display the list of filenames that meet the specified condition and count them\n",
        "print(\"List of filenames with '0' in the specified position:\")\n",
        "for filename in file_list:\n",
        "    # Check if filename meets the condition\n",
        "    parts = filename.split(\"_\")\n",
        "    if len(parts) >= 4:\n",
        "        X = parts[2]\n",
        "        if X == \"‍্য\":\n",
        "            print(filename)\n",
        "            count += 1\n",
        "\n",
        "# Display the count of filenames meeting the condition\n",
        "print(f\"Total number of filenames with '0' in the specified position: {count}\")\n"
      ],
      "metadata": {
        "id": "OrNmXwmc-nnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Replace with your source folder containing the images\n",
        "source_folder = \"/Users/mskamran/Documents/Data Science/letters in different quality image/28*28\"\n",
        "\n",
        "\n",
        "# Replace with your destination folder for images containing \"0\" in the X position\n",
        "destination_folder = \"/Users/mskamran/Documents/Data Science/letters in different quality image/contains_0\"\n",
        "\n",
        "# Ensure destination folder exists\n",
        "os.makedirs(destination_folder, exist_ok=True)  # Create if it doesn't exist\n",
        "\n",
        "# Iterate through files in the source folder\n",
        "for filename in os.listdir(source_folder):\n",
        "    # Split the filename to extract the class_age_X_1632.jpg part\n",
        "    parts = filename.split(\"_\")\n",
        "    if len(parts) >= 4:\n",
        "        # Extract the X part from the filename\n",
        "        X = parts[2]\n",
        "\n",
        "        # Check if X is \"0\"\n",
        "        if X == \"‍্য\":\n",
        "            # Construct source and destination paths\n",
        "            source_path = os.path.join(source_folder, filename)\n",
        "            dest_path = os.path.join(destination_folder, filename)\n",
        "\n",
        "            try:\n",
        "                # Move the image to the destination folder\n",
        "                shutil.move(source_path, dest_path)\n",
        "                print(f\"Moved {filename} to {destination_folder}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error moving {filename}: {e}\")\n",
        "\n",
        "print(\"Image moving completed!\")\n"
      ],
      "metadata": {
        "id": "6-wVkWho_oD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating Many Folders**"
      ],
      "metadata": {
        "id": "1AuGKOVT5RkB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For Old Data"
      ],
      "metadata": {
        "id": "QmsD8wv85aCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "bangla_alphabets = [\n",
        "    'অ', 'ঋ', 'খ', 'জ', 'ঢ', 'ন', 'য', 'হ', 'ো', 'ে', 'ূ', '৪', 'ক্ষ', 'চ্ছ', 'স্থ', 'শ্র',\n",
        "    'আ', 'এ', 'গ', 'ঝ', 'ণ', 'প', 'র', 'ড়', 'ঁ', 'ৈ', 'ৃ', '৫', 'ঞ্চ', 'ন্ত', 'হ্ণ', 'জ্ঞ',\n",
        "    'ই', 'ঐ', 'ঘ', 'ঞ', 'ত', 'ফ', 'ল', 'ঢ়', 'া', 'ো', '০', '৬', 'ঞ্জ', 'ন্ড', 'হ্ন', 'দ্ব',\n",
        "    'ঈ', 'ও', 'ঙ', 'ট', 'থ', 'ব', 'শ', 'য়', 'ি', 'ৌ', '১', '৭', 'ণ্ট', 'স্ত', 'ক্ল', 'ব্ল',\n",
        "    'উ', 'ঔ', 'চ', 'ঠ', 'দ', 'ভ', 'ষ', 'ৎ', 'ী', '্য', '২', '৮', 'ক্ত', 'স্ট', 'ন্দ', 'ম্ন',\n",
        "    'ঊ', 'ক', 'ছ', 'ড', 'ধ', 'ম', 'স', 'ং', 'ু', '্র', '৩', '৯', 'চ্চ', 'স্ত', 'ন্ন'\n",
        "]\n",
        "\n",
        "# Function to create folders within a root folder\n",
        "def create_folders(root_folder, alphabets):\n",
        "    for alphabet in alphabets:\n",
        "        folder_path = os.path.join(root_folder, alphabet)\n",
        "        try:\n",
        "            os.makedirs(folder_path)\n",
        "            print(f\"Folder created: {folder_path}\")\n",
        "        except FileExistsError:\n",
        "            print(f\"Folder already exists: {folder_path}\")\n",
        "\n",
        "# Specify the root folder path\n",
        "root_folder_path = \"//Users/mskamran/Documents/Data Science/letters in different quality image/28*28 letters by seperation\"  # Change this to your desired root folder path\n",
        "\n",
        "# Call the function to create folders within the root folder\n",
        "create_folders(root_folder_path, bangla_alphabets)\n"
      ],
      "metadata": {
        "id": "zEgJIPOY5TPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For New Data"
      ],
      "metadata": {
        "id": "M08yIEwD5eMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "bangla_alphabets = [\n",
        "    'অ', 'আ', 'ই', 'ঈ', 'উ', 'ঊ',\n",
        "    'ঋ', 'এ', 'ঐ', 'ও', 'ঔ', 'ক',\n",
        "    'খ', 'গ', 'ঘ', 'ঙ', 'চ', 'ছ',\n",
        "    'জ', 'ঝ', 'ঞ', 'ট', 'ঠ', 'ড',\n",
        "    'ঢ', 'ণ', 'ত', 'থ', 'দ', 'ধ',\n",
        "    'ন', 'প', 'ফ', 'ব', 'ভ', 'ম',\n",
        "    'য', 'র', 'ল', 'শ', 'ষ', 'স',\n",
        "    'হ', 'ড়', 'ঢ়', 'য়', 'ৎ', 'ং',\n",
        "    'ো', 'ঁ', 'া', 'ি', 'ী', 'ু',\n",
        "    'ে', 'ৈ', 'ৌ', '‍্য', '্র', 'ৃ',\n",
        "    'ূ', 'ঃ', '১', '২', '৩', '৪',\n",
        "    '৫', '৬', '৭', '৮', '৯', '০',\n",
        "    'ক্ষ', 'ঞ্চ', 'ঞ্জ', 'ণ্ট', 'ক্ত', 'ন্ন',\n",
        "    'চ্ছ', 'ন্ত', 'ন্ড', 'স্ত', 'স্ট', 'জ্জ',\n",
        "    'স্থ', 'হ্ণ', 'হ্ন', 'ক্ল', 'ন্দ', 'ত্ম',\n",
        "    'শ্র', 'জ্ঞ', 'দ্ব', 'ব্ল', 'ম্ন', 'দ্ধ'\n",
        "]\n",
        "\n",
        "# Function to create folders within a root folder\n",
        "def create_folders(root_folder, alphabets):\n",
        "    for alphabet in alphabets:\n",
        "        folder_path = os.path.join(root_folder, alphabet)\n",
        "        try:\n",
        "            os.makedirs(folder_path)\n",
        "            print(f\"Folder created: {folder_path}\")\n",
        "        except FileExistsError:\n",
        "            print(f\"Folder already exists: {folder_path}\")\n",
        "\n",
        "# Specify the root folder path\n",
        "root_folder_path = \"//Users/mskamran/Documents/Data Science/letters in different quality image/28*28 letters by seperation\"  # Change this to your desired root folder path\n",
        "\n",
        "# Call the function to create folders within the root folder\n",
        "create_folders(root_folder_path, bangla_alphabets)\n"
      ],
      "metadata": {
        "id": "QPsAvQWA5gJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For Ekush Net"
      ],
      "metadata": {
        "id": "V4PyB8xc5mi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "bangla_alphabets = [\n",
        "    'া', 'ি', 'ী', 'ু', 'ূ', 'ৃ', 'ে', 'ৈ', 'ো', 'ৌ',\n",
        "    'অ', 'আ', 'ই', 'ঈ', 'উ', 'ঊ', 'ঋ', 'এ', 'ঐ', 'ও',\n",
        "    'ঔ', 'ক', 'খ', 'গ', 'ঘ', 'ঙ', 'চ', 'ছ', 'জ', 'ঝ',\n",
        "    'ঞ', 'ট', 'ঠ', 'ড', 'ঢ', 'ণ', 'ত', 'থ', 'দ', 'ধ',\n",
        "    'ন', 'প', 'ফ', 'ব', 'ভ', 'ম', 'য', 'র', 'ল', 'শ',\n",
        "    'ষ', 'স', 'হ', 'ড়', 'ঢ়', 'য়', 'ৎ', 'ং', 'ঃ', 'ঁ',\n",
        "    'ব্দ', 'ঙ্গ', 'স্ক', 'স্ফ', 'চ্ছ', 'স্থ', 'ক্ত', 'স্ন', 'ষ্ণ',\n",
        "    'ম্প', 'প্ত', 'ম্ব', 'ত্থ', 'দ্ভ', 'ষ্ঠ', 'ল্প', 'ষ্প', 'ন্দ', 'ন্ধ',\n",
        "    'স্ম', 'ণ্ঠ', 'স্ত', 'ষ্ট', 'ন্ম', 'ত্ত', 'ঙ্খ', 'ত্ন', 'ন্ড', 'জ্ঞ',\n",
        "    'ড্ড', 'ক্ষ', 'দ্ব', 'চ্চ', 'ক্র', 'দ্দ', 'জ্জ', 'ক্ক', 'ন্ত', 'ক্ট',\n",
        "    'ঞ্চ', 'ট্ট', 'শ্চ', 'ক্স', 'জ্ব', 'ঞ্জ', 'দ্ধ', 'ন্ন', 'ঘ্ন', 'ক্ল',\n",
        "    'হ্ন', 'স্প', 'ল্ত', '0', '1', '2', '3', '4', '5',\n",
        "    '6', '7', '8', '9'\n",
        "]\n",
        "\n",
        "# Function to create folders within a root folder\n",
        "def create_folders(root_folder, alphabets):\n",
        "    for alphabet in alphabets:\n",
        "        folder_path = os.path.join(root_folder, alphabet)\n",
        "        try:\n",
        "            os.makedirs(folder_path)\n",
        "            print(f\"Folder created: {folder_path}\")\n",
        "        except FileExistsError:\n",
        "            print(f\"Folder already exists: {folder_path}\")\n",
        "\n",
        "# Specify the root folder path\n",
        "root_folder_path = \"//Users/mskamran/Documents/Data Science/letters in different quality image/28*28 letters by seperation\"  # Change this to your desired root folder path\n",
        "\n",
        "# Call the function to create folders within the root folder\n",
        "create_folders(root_folder_path, bangla_alphabets)\n"
      ],
      "metadata": {
        "id": "nN9IjZIA5ohS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Copy Folder Structure and Resize the Image"
      ],
      "metadata": {
        "id": "MzMJxMMg6CZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Function to resize images in a folder and its subfolders\n",
        "def resize_images(input_folder, output_folder, target_size=(256, 256)):\n",
        "    # Iterate through all files and subfolders in the input folder\n",
        "    for root, dirs, files in os.walk(input_folder):\n",
        "        # Create corresponding subfolders in the output directory\n",
        "        rel_path = os.path.relpath(root, input_folder)\n",
        "        output_subfolder = os.path.join(output_folder, rel_path)\n",
        "        os.makedirs(output_subfolder, exist_ok=True)\n",
        "\n",
        "        for file in files:\n",
        "            # Check if the file is an image\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
        "                input_path = os.path.join(root, file)\n",
        "                output_path = os.path.join(output_subfolder, file)\n",
        "\n",
        "                # Open the image file\n",
        "                with Image.open(input_path) as img:\n",
        "                    # Resize the image\n",
        "                    img_resized = img.resize(target_size)\n",
        "\n",
        "                    # Save the resized image\n",
        "                    img_resized.save(output_path)\n",
        "\n",
        "# Example usage\n",
        "input_folder = \"/Users/mskamran/Documents/Data Science/letters in different quality image/512 letter by augment\"\n",
        "output_folder = \"/Users/mskamran/Documents/Data Science/letters in different quality image/256 letter by aug\"\n",
        "resize_images(input_folder, output_folder, target_size=(256, 256))\n"
      ],
      "metadata": {
        "id": "YWj13B-w6Bvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Move Letters to Its Folder**"
      ],
      "metadata": {
        "id": "12iMoDUuAXgu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Old Data"
      ],
      "metadata": {
        "id": "AXkUHpHWAiQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Bangla alphabets\n",
        "bangla_alphabets = [\n",
        "    'অ', 'ঋ', 'খ', 'জ', 'ঢ', 'ন', 'য', 'হ', 'ো', 'ে', 'ূ', '৪', 'ক্ষ', 'চ্ছ', 'স্থ', 'শ্র',\n",
        "    'আ', 'এ', 'গ', 'ঝ', 'ণ', 'প', 'র', 'ড়', 'ঁ', 'ৈ', 'ৃ', '৫', 'ঞ্চ', 'ন্ত', 'হ্ণ', 'জ্ঞ',\n",
        "    'ই', 'ঐ', 'ঘ', 'ঞ', 'ত', 'ফ', 'ল', 'ঢ়', 'া' , 'ো', '০', '৬', 'ঞ্জ', 'ন্ড', 'হ্ন', 'দ্ব',\n",
        "    'ঈ', 'ও', 'ঙ', 'ট', 'থ', 'ব', 'শ', 'য়', 'ি', ' ৌ', '১', '৭', 'ণ্ট', 'স্ত', 'ক্ল', 'ব্ল',\n",
        "    'উ', 'ঔ', 'চ', 'ঠ', 'দ', 'ভ', 'ষ', 'ৎ', 'ী', '‍্য', '২', '৮', 'ক্ত', 'স্ট', 'ন্দ', 'ম্ন',\n",
        "    'ঊ', 'ক', 'ছ', 'ড', 'ধ', 'ম', 'স', 'ং', 'ু', '্র', '৩', '৯', 'চ্চ', 'স্ত', 'ন্ন'\n",
        "]\n",
        "\n",
        "# Replace with your source folder containing the images\n",
        "source_folder = \"/Users/mskamran/Documents/Data Science/letters in different quality image/28*28 revere\"\n",
        "\n",
        "# Base destination folder\n",
        "base_destination_folder = \"/Users/mskamran/Documents/Data Science/letters in different quality image/28*28 letter by reverse\"\n",
        "\n",
        "# Ensure base destination folder exists\n",
        "os.makedirs(base_destination_folder, exist_ok=True)  # Create if it doesn't exist\n",
        "\n",
        "# List all files in the source folder\n",
        "all_files = os.listdir(source_folder)\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 1000\n",
        "\n",
        "# Calculate the number of batches\n",
        "num_batches = len(all_files) // batch_size + 1\n",
        "\n",
        "for batch_idx in range(num_batches):\n",
        "    # Get start and end index for the current batch\n",
        "    start_idx = batch_idx * batch_size\n",
        "    end_idx = min((batch_idx + 1) * batch_size, len(all_files))\n",
        "\n",
        "    # Iterate through files in the current batch\n",
        "    for filename in all_files[start_idx:end_idx]:\n",
        "        # Split the filename to extract the class_age_X_1632.jpg part\n",
        "        parts = filename.split(\"_\")\n",
        "        if len(parts) >= 4:\n",
        "            # Extract the X part from the filename\n",
        "            letter = parts[2]\n",
        "\n",
        "            # Check if the letter is in Bangla alphabets\n",
        "            if letter in bangla_alphabets:\n",
        "                # Get the corresponding destination folder name\n",
        "                destination_folder = os.path.join(base_destination_folder, letter)\n",
        "\n",
        "                # Ensure destination folder exists for the letter\n",
        "                os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "                # Construct source and destination paths\n",
        "                source_path = os.path.join(source_folder, filename)\n",
        "                dest_path = os.path.join(destination_folder, filename)\n",
        "\n",
        "                # Move the image to the destination folder\n",
        "                shutil.move(source_path, dest_path)\n",
        "\n",
        "    print(f\"Batch {batch_idx+1}/{num_batches} completed\")\n",
        "\n",
        "print(\"Image moving completed!\")\n"
      ],
      "metadata": {
        "id": "Flxtmp2xAcEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Data"
      ],
      "metadata": {
        "id": "-So7662PAlny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Bangla alphabets\n",
        "bangla_alphabets = [\n",
        "    'অ', 'আ', 'ই', 'ঈ', 'উ', 'ঊ',\n",
        "    'ঋ', 'এ', 'ঐ', 'ও', 'ঔ', 'ক',\n",
        "    'খ', 'গ', 'ঘ', 'ঙ', 'চ', 'ছ',\n",
        "    'জ', 'ঝ', 'ঞ', 'ট', 'ঠ', 'ড',\n",
        "    'ঢ', 'ণ', 'ত', 'থ', 'দ', 'ধ',\n",
        "    'ন', 'প', 'ফ', 'ব', 'ভ', 'ম',\n",
        "    'য', 'র', 'ল', 'শ', 'ষ', 'স',\n",
        "    'হ', 'ড়', 'ঢ়', 'য়', 'ৎ', 'ং',\n",
        "    'ো', 'ঁ', 'া', 'ি', 'ী', 'ু',\n",
        "    'ে', 'ৈ', 'ৌ', '‍্য', '্র', 'ৃ',\n",
        "    'ূ', 'ঃ', '১', '২', '৩', '৪',\n",
        "    '৫', '৬', '৭', '৮', '৯', '০',\n",
        "    'ক্ষ', 'ঞ্চ', 'ঞ্জ', 'ণ্ট', 'ক্ত', 'ন্ন',\n",
        "    'চ্ছ', 'ন্ত', 'ন্ড', 'স্ত', 'স্ট', 'জ্জ',\n",
        "    'স্থ', 'হ্ণ', 'হ্ন', 'ক্ল', 'ন্দ', 'ত্ম',\n",
        "    'শ্র', 'জ্ঞ', 'দ্ব', 'ব্ল', 'ম্ন', 'দ্ধ'\n",
        "]\n",
        "\n",
        "# Replace with your source folder containing the images\n",
        "source_folder = \"/Users/mskamran/Documents/Data Science/letters in different quality image/28*28 revere\"\n",
        "\n",
        "# Base destination folder\n",
        "base_destination_folder = \"/Users/mskamran/Documents/Data Science/letters in different quality image/28*28 letter by reverse\"\n",
        "\n",
        "# Ensure base destination folder exists\n",
        "os.makedirs(base_destination_folder, exist_ok=True)  # Create if it doesn't exist\n",
        "\n",
        "# List all files in the source folder\n",
        "all_files = os.listdir(source_folder)\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 1000\n",
        "\n",
        "# Calculate the number of batches\n",
        "num_batches = len(all_files) // batch_size + 1\n",
        "\n",
        "for batch_idx in range(num_batches):\n",
        "    # Get start and end index for the current batch\n",
        "    start_idx = batch_idx * batch_size\n",
        "    end_idx = min((batch_idx + 1) * batch_size, len(all_files))\n",
        "\n",
        "    # Iterate through files in the current batch\n",
        "    for filename in all_files[start_idx:end_idx]:\n",
        "        # Split the filename to extract the class_age_X_1632.jpg part\n",
        "        parts = filename.split(\"_\")\n",
        "        if len(parts) >= 4:\n",
        "            # Extract the X part from the filename\n",
        "            letter = parts[2]\n",
        "\n",
        "            # Check if the letter is in Bangla alphabets\n",
        "            if letter in bangla_alphabets:\n",
        "                # Get the corresponding destination folder name\n",
        "                destination_folder = os.path.join(base_destination_folder, letter)\n",
        "\n",
        "                # Ensure destination folder exists for the letter\n",
        "                os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "                # Construct source and destination paths\n",
        "                source_path = os.path.join(source_folder, filename)\n",
        "                dest_path = os.path.join(destination_folder, filename)\n",
        "\n",
        "                # Move the image to the destination folder\n",
        "                shutil.move(source_path, dest_path)\n",
        "\n",
        "    print(f\"Batch {batch_idx+1}/{num_batches} completed\")\n",
        "\n",
        "print(\"Image moving completed!\")\n"
      ],
      "metadata": {
        "id": "E5c_saN3An9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ekush Net"
      ],
      "metadata": {
        "id": "epqZ6IOiBAml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Bangla alphabets\n",
        "bangla_alphabets = [\n",
        "    'া', 'ি', 'ী', 'ু', 'ূ', 'ৃ', 'ে', 'ৈ', 'ো', 'ৌ',\n",
        "    'অ', 'আ', 'ই', 'ঈ', 'উ', 'ঊ', 'ঋ', 'এ', 'ঐ', 'ও',\n",
        "    'ঔ', 'ক', 'খ', 'গ', 'ঘ', 'ঙ', 'চ', 'ছ', 'জ', 'ঝ',\n",
        "    'ঞ', 'ট', 'ঠ', 'ড', 'ঢ', 'ণ', 'ত', 'থ', 'দ', 'ধ',\n",
        "    'ন', 'প', 'ফ', 'ব', 'ভ', 'ম', 'য', 'র', 'ল', 'শ',\n",
        "    'ষ', 'স', 'হ', 'ড়', 'ঢ়', 'য়', 'ৎ', 'ং', 'ঃ', 'ঁ',\n",
        "    'ব্দ', 'ঙ্গ', 'স্ক', 'স্ফ', 'চ্ছ', 'স্থ', 'ক্ত', 'স্ন', 'ষ্ণ',\n",
        "    'ম্প', 'প্ত', 'ম্ব', 'ত্থ', 'দ্ভ', 'ষ্ঠ', 'ল্প', 'ষ্প', 'ন্দ', 'ন্ধ',\n",
        "    'স্ম', 'ণ্ঠ', 'স্ত', 'ষ্ট', 'ন্ম', 'ত্ত', 'ঙ্খ', 'ত্ন', 'ন্ড', 'জ্ঞ',\n",
        "    'ড্ড', 'ক্ষ', 'দ্ব', 'চ্চ', 'ক্র', 'দ্দ', 'জ্জ', 'ক্ক', 'ন্ত', 'ক্ট',\n",
        "    'ঞ্চ', 'ট্ট', 'শ্চ', 'ক্স', 'জ্ব', 'ঞ্জ', 'দ্ধ', 'ন্ন', 'ঘ্ন', 'ক্ল',\n",
        "    'হ্ন', 'স্প', 'ল্ত', '0', '1', '2', '3', '4', '5',\n",
        "    '6', '7', '8', '9'\n",
        "]\n",
        "\n",
        "# Replace with your source folder containing the images\n",
        "source_folder = \"/Users/mskamran/Documents/Data Science/letters in different quality image/28*28 revere\"\n",
        "\n",
        "# Base destination folder\n",
        "base_destination_folder = \"/Users/mskamran/Documents/Data Science/letters in different quality image/28*28 letter by reverse\"\n",
        "\n",
        "# Ensure base destination folder exists\n",
        "os.makedirs(base_destination_folder, exist_ok=True)  # Create if it doesn't exist\n",
        "\n",
        "# List all files in the source folder\n",
        "all_files = os.listdir(source_folder)\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 1000\n",
        "\n",
        "# Calculate the number of batches\n",
        "num_batches = len(all_files) // batch_size + 1\n",
        "\n",
        "for batch_idx in range(num_batches):\n",
        "    # Get start and end index for the current batch\n",
        "    start_idx = batch_idx * batch_size\n",
        "    end_idx = min((batch_idx + 1) * batch_size, len(all_files))\n",
        "\n",
        "    # Iterate through files in the current batch\n",
        "    for filename in all_files[start_idx:end_idx]:\n",
        "        # Split the filename to extract the class_age_X_1632.jpg part\n",
        "        parts = filename.split(\"_\")\n",
        "        if len(parts) >= 4:\n",
        "            # Extract the X part from the filename\n",
        "            letter = parts[2]\n",
        "\n",
        "            # Check if the letter is in Bangla alphabets\n",
        "            if letter in bangla_alphabets:\n",
        "                # Get the corresponding destination folder name\n",
        "                destination_folder = os.path.join(base_destination_folder, letter)\n",
        "\n",
        "                # Ensure destination folder exists for the letter\n",
        "                os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "                # Construct source and destination paths\n",
        "                source_path = os.path.join(source_folder, filename)\n",
        "                dest_path = os.path.join(destination_folder, filename)\n",
        "\n",
        "                # Move the image to the destination folder\n",
        "                shutil.move(source_path, dest_path)\n",
        "\n",
        "    print(f\"Batch {batch_idx+1}/{num_batches} completed\")\n",
        "\n",
        "print(\"Image moving completed!\")\n"
      ],
      "metadata": {
        "id": "22l4fVHeBC9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Augmente the data**"
      ],
      "metadata": {
        "id": "dCJwgb07BUGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from PIL import Image, ImageEnhance, ImageOps\n",
        "\n",
        "# Define the path to your main folder containing subfolders with images\n",
        "main_folder = \"/Users/mskamran/Documents/Data Science/letters in different quality image/try/untitled folder\"   #folder containing subfolders with images\n",
        "\n",
        "# Define the number of images you want to augment to (1000)\n",
        "target_count = 5\n",
        "\n",
        "# Define augmentation parameters\n",
        "rotation_angles = [90, 45, 45] #Rotion angles (in degrees)\n",
        "brightness_factors = [0.5, 1.5]   # Brightness factors (0.5 means darker, 1.5 means brighter)\n",
        "\n",
        "# Function to perform augmentation on a single image\n",
        "def augment_image(image):\n",
        "    augmented_images = [image]  # Start with the original image\n",
        "    # Rotation\n",
        "    for angle in rotation_angles:\n",
        "        rotated_image = image.rotate(angle)\n",
        "        augmented_images.append(rotated_image)\n",
        "    # Brightness adjustment\n",
        "    for factor in brightness_factors:\n",
        "        enhanced_image = ImageEnhance.Brightness(image).enhance(factor)\n",
        "        augmented_images.append(enhanced_image)\n",
        "    return augmented_images\n",
        "\n",
        "# Iterate through each subfolder in the main folder\n",
        "for folder_name in os.listdir(main_folder):\n",
        "    folder_path = os.path.join(main_folder, folder_name)\n",
        "    if os.path.isdir(folder_path):\n",
        "        # Check if the number of images in the folder is less than the target count\n",
        "        existing_images = os.listdir(folder_path)\n",
        "        num_existing_images = len(existing_images)\n",
        "        if num_existing_images < target_count:\n",
        "            # Augment existing images and save them until reaching the target count\n",
        "            while num_existing_images < target_count:\n",
        "                # Choose a random existing image to augment\n",
        "                random_image_name = random.choice(existing_images)\n",
        "                random_image_path = os.path.join(folder_path, random_image_name)\n",
        "                # Open the image\n",
        "                with Image.open(random_image_path) as img:\n",
        "                    # Augment the image\n",
        "                    augmented_images = augment_image(img)\n",
        "                    # Save augmented images\n",
        "                    for i, augmented_img in enumerate(augmented_images):\n",
        "                        new_image_name = f\"{i}_{random_image_name}\"  # Prefix with index to avoid overwriting\n",
        "                        new_image_path = os.path.join(folder_path, new_image_name)\n",
        "                        augmented_img.save(new_image_path)\n",
        "                        num_existing_images += 1\n",
        "                        # Check if the target count is reached\n",
        "                        if num_existing_images >= target_count:\n",
        "                            break\n"
      ],
      "metadata": {
        "id": "m9gdzEZzBXTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from PIL import Image, ImageEnhance, ImageOps, ImageFilter\n",
        "\n",
        "# Define the main folder containing subfolders with images\n",
        "main_folder = \"/Users/mskamran/Documents/Data Science/letters in different quality image/512 letter by augment copy\"\n",
        "\n",
        "# Define the number of augmented images to create\n",
        "num_augmented_images = 1200\n",
        "\n",
        "# Define augmentation parameters\n",
        "rotation_angles = [90, 45, -45]  # Rotation angles (in degrees)\n",
        "brightness_factors = [0.5, 1.5]  # Brightness factors (0.5 means darker, 1.5 means brighter)\n",
        "contrast_factors = [0.5, 1.5]    # Contrast factors (0.5 means less contrast, 1.5 means more contrast)\n",
        "sharpness_factors = [0.5, 1.5]   # Sharpness factors (0.5 means less sharpness, 1.5 means more sharpness)\n",
        "\n",
        "# Additional augmentation parameters\n",
        "crop_sizes = [(0.8, 0.8), (0.9, 0.9)]  # Crop sizes (percentage of original size)\n",
        "blur_radii = [1, 2]  # Blur radii (kernel size)\n",
        "noise_levels = [0.1, 0.2]  # Noise levels\n",
        "\n",
        "# Function to perform augmentation on a single image\n",
        "def augment_image(image):\n",
        "    augmented_images = []  # Initialize list for augmented images\n",
        "    # Rotation\n",
        "    for angle in rotation_angles:\n",
        "        rotated_image = image.rotate(angle, fillcolor='white')  # Fill with white color after rotation\n",
        "        augmented_images.append(rotated_image)\n",
        "    # Brightness adjustment\n",
        "    for factor in brightness_factors:\n",
        "        enhanced_image = ImageEnhance.Brightness(image).enhance(factor)\n",
        "        augmented_images.append(enhanced_image)\n",
        "    # Contrast adjustment\n",
        "    for factor in contrast_factors:\n",
        "        enhanced_image = ImageEnhance.Contrast(image).enhance(factor)\n",
        "        augmented_images.append(enhanced_image)\n",
        "    # Sharpness adjustment\n",
        "    for factor in sharpness_factors:\n",
        "        enhanced_image = ImageEnhance.Sharpness(image).enhance(factor)\n",
        "        augmented_images.append(enhanced_image)\n",
        "    # Crop and Resize\n",
        "    for size in crop_sizes:\n",
        "        cropped_image = image.crop((0, 0, size[0]*image.width, size[1]*image.height))\n",
        "        resized_image = cropped_image.resize((image.width, image.height))\n",
        "        augmented_images.append(resized_image)\n",
        "    # Gaussian Blur\n",
        "    for radius in blur_radii:\n",
        "        blurred_image = image.filter(ImageFilter.GaussianBlur(radius))\n",
        "        augmented_images.append(blurred_image)\n",
        "    # Noise Injection\n",
        "    for level in noise_levels:\n",
        "        noisy_image = apply_noise(image, level)\n",
        "        augmented_images.append(noisy_image)\n",
        "    return augmented_images\n",
        "\n",
        "# Function to apply noise to the image\n",
        "def apply_noise(image, level):\n",
        "    width, height = image.size\n",
        "    noisy_image = Image.new(\"RGB\", (width, height))\n",
        "    pixels = noisy_image.load()\n",
        "    for x in range(width):\n",
        "        for y in range(height):\n",
        "            r, g, b = image.getpixel((x, y))\n",
        "            noise = random.randint(-int(255*level), int(255*level))\n",
        "            r = min(255, max(0, r + noise))\n",
        "            g = min(255, max(0, g + noise))\n",
        "            b = min(255, max(0, b + noise))\n",
        "            pixels[x, y] = (r, g, b)\n",
        "    return noisy_image\n",
        "\n",
        "# Function to iterate through folders and augment images\n",
        "def augment_images_in_folder(folder_path):\n",
        "    for subdir, dirs, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            if file.endswith(('.jpg', '.jpeg', '.png')):  # Filter only image files\n",
        "                image_path = os.path.join(subdir, file)\n",
        "                with Image.open(image_path) as img:\n",
        "                    augmented_images = augment_image(img)\n",
        "                    for i, augmented_img in enumerate(augmented_images):\n",
        "                        new_image_name = f\"{i+1}_{file}\"\n",
        "                        new_image_path = os.path.join(subdir, new_image_name)\n",
        "                        augmented_img.save(new_image_path)\n",
        "\n",
        "# Augment images in the main folder and its subfolders\n",
        "augment_images_in_folder(main_folder)\n",
        "\n",
        "print(\"Augmentation completed.\")\n"
      ],
      "metadata": {
        "id": "R8ov5I3wBZ-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Letters in Reverse Black And White**"
      ],
      "metadata": {
        "id": "cL3QtzvUBeh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Source folder containing the images\n",
        "source_folder = \"/Users/mskamran/Documents/Data Science/letters in different quality image/28*28 letter by augmentation\"\n",
        "\n",
        "# Destination folder to save the converted images\n",
        "destination_folder = \"/Users/mskamran/Documents/Data Science/letters in different quality image/28*28 letter by revere\"\n",
        "\n",
        "# Ensure destination folder exists\n",
        "os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "# List all files in the source folder\n",
        "files = os.listdir(source_folder)\n",
        "\n",
        "# Process each image file\n",
        "for file in files:\n",
        "    # Construct the path to the input image\n",
        "    input_path = os.path.join(source_folder, file)\n",
        "\n",
        "    # Open the image\n",
        "    with Image.open(input_path) as img:\n",
        "        # Convert the image to grayscale (black and white)\n",
        "        bw_img = img.convert(\"L\")\n",
        "\n",
        "        # Reverse the colors (black to white, white to black)\n",
        "        inverted_img = Image.eval(bw_img, lambda px: 255 - px)\n",
        "\n",
        "        # Construct the path to save the output image\n",
        "        output_path = os.path.join(destination_folder, file)\n",
        "\n",
        "        # Save the inverted image\n",
        "        inverted_img.save(output_path)\n",
        "\n",
        "        print(f\"Processed: {file} -> Saved as: {output_path}\")\n",
        "\n",
        "print(\"Image processing completed!\")"
      ],
      "metadata": {
        "id": "co1LLOxhBh2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Crop Just Letters Without Size White Box**"
      ],
      "metadata": {
        "id": "iZRcRaZDDeVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Read the image\n",
        "img = cv2.imread('/content/drive/MyDrive/OCR Thesis/Kishoregonj/Image with dotted lines/raw/IMG_20230916_212643.jpg')\n",
        "\n",
        "# Convert the image to grayscale\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Apply Gaussian blur to reduce noise\n",
        "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "# Perform edge detection using Canny\n",
        "edges = cv2.Canny(blurred, 50, 150)\n",
        "\n",
        "# Find contours in the edged image\n",
        "contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# Get the largest contour\n",
        "largest_contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "# Get the bounding box of the largest contour\n",
        "x, y, w, h = cv2.boundingRect(largest_contour)\n",
        "\n",
        "# Crop the image using the bounding box\n",
        "cropped_image = img[y:y+h, x:x+w]\n",
        "\n",
        "# Display the cropped image\n",
        "plt.imshow(cropped_image)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gZckPOfSDmHt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}